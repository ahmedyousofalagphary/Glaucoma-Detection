{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Glaucoma Detection Using Pre-Trained Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c265041f4e944d4d83c80380b5e7cc7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ba79510f29ea44bea0f215df320d8908",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4dca1c1794ca4facae0483bef789d014",
              "IPY_MODEL_91dcdd222a7847d5a0cccbf4287e3746"
            ]
          }
        },
        "ba79510f29ea44bea0f215df320d8908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4dca1c1794ca4facae0483bef789d014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1922b142ddc34a4fae4d800149042b85",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 531456000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 531456000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ad7be4841744ed08180e2732c7e7da1"
          }
        },
        "91dcdd222a7847d5a0cccbf4287e3746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c4189c15166547d1bf604ef28a2821b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 507M/507M [00:07&lt;00:00, 72.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_841e0750830741798deb8584938f9f40"
          }
        },
        "1922b142ddc34a4fae4d800149042b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ad7be4841744ed08180e2732c7e7da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4189c15166547d1bf604ef28a2821b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "841e0750830741798deb8584938f9f40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b9bb6fee1f04a26829784abad05b422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb5cdc93fac341a28583e22412648f4c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a0a988d6067246e680c196a497673f6f",
              "IPY_MODEL_c9894ef3731c4c899419a0b497c113ef"
            ]
          }
        },
        "fb5cdc93fac341a28583e22412648f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0a988d6067246e680c196a497673f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1cdafb8dc4814bee85df10c48841078b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60fcdaf83354461ba085fe71945535b6"
          }
        },
        "c9894ef3731c4c899419a0b497c113ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_af6ab9da84d94718a185c58cdd81d5e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:25&lt;00:00, 21.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c909c48f19a14e54af3b027162cefdd5"
          }
        },
        "1cdafb8dc4814bee85df10c48841078b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60fcdaf83354461ba085fe71945535b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af6ab9da84d94718a185c58cdd81d5e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c909c48f19a14e54af3b027162cefdd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13c1cf499cca450199193ece5a66d783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d32d8616aba84540a97a71e6179a31c8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b5a51125215246e9b6c0acaf84e0d71c",
              "IPY_MODEL_e3871cff84744ef4ba165a06017fc64c"
            ]
          }
        },
        "d32d8616aba84540a97a71e6179a31c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5a51125215246e9b6c0acaf84e0d71c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e04b636bb33b4a7793a0ecb064050fc5",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51ac87b23971469a851d9e9d93fed207"
          }
        },
        "e3871cff84744ef4ba165a06017fc64c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b8814c1990e1499eac510a1eb8b1c8e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [08:18&lt;00:00, 1.15MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e1c3294528e42f2a0559dba3105a76c"
          }
        },
        "e04b636bb33b4a7793a0ecb064050fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51ac87b23971469a851d9e9d93fed207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8814c1990e1499eac510a1eb8b1c8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e1c3294528e42f2a0559dba3105a76c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhFt13qJCMcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee4fb8ba-7822-448c-9898-f594bdb98d42"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/glacomadataset2.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/glacomadataset2.zip\n",
            "   creating: glacomadataset2/\n",
            "   creating: glacomadataset2/glaucoma/\n",
            "  inflating: glacomadataset2/glaucoma/image100prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image101prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image102prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image103prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image104prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image105prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image106prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image107prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image108prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image109prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image10prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image10prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image110prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image111prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image112prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image113prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image114prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image115prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image116prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image117prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image118prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image119prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image11prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image11prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image120prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image121prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image122prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image123prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image124prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image125prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image126prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image127prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image128prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image129prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image12prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image12prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image130prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image131prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image132prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image133prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image134prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image135prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image136prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image137prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image138prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image139prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image13prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image13prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image140prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image141prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image142prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image143prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image144prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image145prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image146prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image147prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image148prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image149prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image14prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image14prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image150prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image151prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image152prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image153prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image154prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image155prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image156prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image157prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image158prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image159prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image15prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image15prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image160prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image161prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image162prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image163prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image164prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image165prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image166prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image167prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image168prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image169prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image16prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image16prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image170prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image171prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image172prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image173prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image174prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image175prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image176prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image177prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image178prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image179prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image17prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image17prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image180prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image181prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image182prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image183prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image184prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image185prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image186prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image187prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image188prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image189prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image18prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image18prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image190prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image191prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image192prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image193prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image194prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image195prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image196prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image197prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image198prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image199prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image19prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image19prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image1prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image1prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image200prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image201prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image202prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image203prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image204prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image205prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image206prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image207prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image208prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image209prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image20prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image20prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image210prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image211prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image212prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image213prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image214prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image215prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image216prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image217prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image218prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image219prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image21prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image21prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image220prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image221prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image222prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image223prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image224prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image225prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image226prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image227prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image228prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image229prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image22prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image22prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image230prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image231prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image232prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image233prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image234prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image235prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image236prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image237prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image238prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image239prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image23prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image23prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image240prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image241prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image242prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image243prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image244prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image245prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image246prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image247prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image248prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image249prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image24prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image24prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image250prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image251prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image252prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image253prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image254prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image255prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image256prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image257prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image258prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image259prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image25prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image25prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image260prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image261prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image262prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image263prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image264prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image265prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image266prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image267prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image268prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image269prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image26prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image26prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image270prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image271prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image272prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image273prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image274prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image275prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image276prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image277prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image278prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image279prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image27prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image27prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image280prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image281prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image282prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image283prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image284prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image285prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image286prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image287prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image288prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image289prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image28prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image28prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image290prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image291prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image292prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image293prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image294prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image295prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image296prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image297prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image298prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image299prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image29prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image29prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image2prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image2prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image300prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image301prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image302prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image303prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image304prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image305prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image306prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image307prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image308prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image309prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image30prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image30prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image310prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image311prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image312prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image313prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image314prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image315prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image316prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image317prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image318prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image319prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image31prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image31prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image320prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image321prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image322prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image323prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image324prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image325prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image326prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image327prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image328prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image329prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image32prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image32prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image330prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image331prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image332prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image333prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image334prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image335prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image336prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image337prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image338prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image339prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image33prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image33prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image340prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image341prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image342prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image343prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image344prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image345prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image346prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image347prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image348prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image349prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image34prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image34prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image350prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image351prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image352prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image353prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image354prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image355prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image356prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image357prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image358prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image359prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image35prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image35prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image360prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image361prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image362prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image363prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image364prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image365prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image366prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image367prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image368prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image369prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image36prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image36prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image370prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image371prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image372prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image373prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image374prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image375prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image376prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image377prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image378prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image379prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image37prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image37prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image380prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image381prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image382prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image383prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image384prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image385prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image386prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image387prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image388prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image389prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image38prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image38prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image390prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image391prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image392prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image393prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image394prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image395prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image396prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image397prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image398prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image399prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image39prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image39prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image3prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image3prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image400prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image401prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image402prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image403prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image404prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image405prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image406prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image407prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image408prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image409prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image40prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image40prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image410prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image411prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image412prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image413prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image414prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image415prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image416prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image417prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image418prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image419prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image41prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image41prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image420prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image421prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image422prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image423prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image424prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image425prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image426prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image427prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image428prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image429prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image42prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image42prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image430prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image431prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image432prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image433prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image434prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image435prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image436prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image437prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image438prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image439prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image43prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image43prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image440prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image441prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image442prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image443prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image444prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image445prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image446prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image447prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image448prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image449prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image44prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image44prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image450prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image451prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image452prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image453prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image454prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image455prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image456prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image457prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image458prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image459prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image45prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image45prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image460prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image46prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image46prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image47prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image47prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image48prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image48prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image49prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image49prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image4prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image4prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image50prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image50prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image51prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image51prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image52prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image53prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image54prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image55prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image56prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image57prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image58prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image59prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image5prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image5prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image60prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image61prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image62prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image63prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image64prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image65prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image66prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image67prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image68prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image69prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image6prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image6prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image70prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image71prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image72prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image73prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image74prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image75prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image76prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image77prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image78prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image79prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image7prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image7prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image80prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image81prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image82prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image83prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image84prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image85prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image86prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image87prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image88prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image89prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image8prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image8prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image90prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image91prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image92prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image93prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image94prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image95prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image96prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image97prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image98prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image99prime.jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image9prime (2).jpg  \n",
            "  inflating: glacomadataset2/glaucoma/image9prime.jpg  \n",
            "   creating: glacomadataset2/not_glaucoma/\n",
            "  inflating: glacomadataset2/not_glaucoma/401fdfd0db07.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4029d70e9d8a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/404ede327e98.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/40c24aded50c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/40dd4e6e4444.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4158c340fa49.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4189d4e631ec.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/419406328dcd.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4210809074c1.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4242c0d87f57.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4276b82e4489.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4289af3afbd2.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/42985aa2e32f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/43823561c3f0.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4384fa687afa.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4393c5bc576a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/43f22d1be8dd.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/441848e0f308.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4464bb62bf20.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4478b870e549.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/44855f666225.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4489d421e5aa.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/44976c3b11a6.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/44f4ae58990e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/453a1e2754b2.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/454a944eb557.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4554062fa836.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/45693d027798.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/45ae04cfde5d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/45e4b7eada54.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/462937ece243.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4689b739d240.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/46acc506fa61.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/46cdc8b685bd.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/47536db39f00.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/47b756014447.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4818672273af.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4826d10030b3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4860f7813654.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/486e852a3b4d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/48a45619d1a3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/48fda42bd5d4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4926dea289f8.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/49419f8d5cb4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/495255c7492f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4958bfcc9f38.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/49e4b95ee2dc.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/4a0bba3b7d83.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a11bf2edd470.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a14fcf84bfe1.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a15590a7d774.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a1872f9c0cba.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a1b28bcbce00.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a1e236fbc863.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a21b37719f9b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a2811f512c1c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a28bfb772f50.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a3132c8828e4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a32b5ce3d48a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a3706ce27869.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a3ad6c2db6f1.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a3b2e93d058b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a3bd2e034614.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a3d2a0c4cd17.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a3fcf42ff56d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a4012932e18d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a44345b27804.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a4b8de38eac1.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a5bb85afc6e8.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a6356a3c5d11.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a64273801bde.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a6731dd737af.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a688f20f8895.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a6b6d27c1b32.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a73c3d516c59.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a73d012c4c38.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a76132e79688.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a7673ac44509.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a77dbec966d4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a7b7dc8788b9.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a7c10ca6c117.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a7ec056502e7.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a8652b2de23f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a88365134c3c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a8854768549f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a88f68b0b114.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a8a6588c8eb7.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a8c54e2a4b79.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a8dea22ef903.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a8e08e7fe016.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a8eb35b3bcd2.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a963ac561580.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a987aa7aac37.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a9dc80cba9a4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/a9e984b57556.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/aa4407aab872.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/aa5ce75edcf5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/aa60813e1a8d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/aa6242f9e08c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/aa6673241154.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/aa841de1ee82.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/aa8a1e814811.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/aabd867043cf.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/aad0c0ee9268.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ab03d50bba2f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ab32db41c409.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ab50123abadb.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ab653b8554c0.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ab78a66dee6a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/aba3063c5413.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ababe19ed448.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/abe940882578.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ac1667fac512.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ac17cc18a994.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ac2c814949f9.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ac81fc200162.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/acc9f29538c4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ace2281f00c4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ad12cde115ab.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ad6b07d5c338.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ad93d88c87ea.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/addf66a50f42.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ae20112e7a1e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ae2c3f6312ef.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ae49cc60f251.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ae57c8630249.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ae8424cdb029.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/aea59ebec445.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/aeb6f4fd2eed.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/aed4e743c230.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/aef9016557ca.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/af133a85ea0c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/af345c68e836.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/af3b0115aad1.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/af5a0bc4e1fa.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/af7a36454670.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/af828dab3ffc.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/afc744fad65e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b033ab4fb723.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b05922e7abd3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b07bc463b718.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b0b3b16fc305.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b0cc9f8d06e4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b0f8613305a3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b1197f2cc9b3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b16dd4483ca5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b1c6f0997e27.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b1f4122fd36a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b22354b5f94b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b2aaa81cc8f0.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b2b7ccd34cbd.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b3819a805dca.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b3d12069e1c5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b402b18d99a5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b49b2fac2514.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b4b04d81acbb.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b4e15102cd7a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b4f41b5bf0ef.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b553e7909535.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b56340f472d2.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b5a3ca5c0a80.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b5c80d0ed0ff.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b66f23ffa730.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b6bf847fbcb2.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b6bfe9db60e5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b6fd109b1bc9.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b70e7c26f51e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b71428739d4e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b746a6681ba9.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b74de20d73de.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b7983cb3f270.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b7aca95b97b9.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b7e0f95353f2.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b82d5f1f1145.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b89938407ee6.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b8ebedd382de.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b90bc89ce8d8.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b9127e38d9b9.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b927a9238434.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b95d4dd8e5e2.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b960142a8de7.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b99794a0beed.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/b9bc81fcb075.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ba08cee68c71.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ba4e62c11cc0.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bac1744955c2.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bacfa2b8e706.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bacfb1029f6b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/badb5ff8d3c7.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bb08949dd70a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bb2f89488ecd.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bb45257258cc.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bc7bf19b84e3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bcb0498ed2c1.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bcc762618e7d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bcd503c726ba.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bcdc8db5423b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bd34a0639575.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bdb98063fe84.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/be21d8b60e2a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/be3a7d9e981e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/be521870a0ea.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/be6cbf6e5b10.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/be7bc89f5fec.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/be7f791a7877.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/beb2ad14fd2d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/beeca5f14618.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bf18ff30a8f6.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bf1b7e21e774.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bf7047dc683c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bf87aedf2489.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bf9cba745efc.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/bfda2fd0533a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c0202976c670.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c05b7b4c22fe.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c06024f05a16.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c0968d41eb93.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c12e9ca420a5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c280730cc211.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c2a58b2cfd0b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c2f3281cf528.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c334f8688b77.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c373b73a80c8.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c3a82acb7d7a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c48ae5da188e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c4aef0d88d1b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c57c164bca05.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c58971bcebb2.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c58e5c0c5b33.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c597ef460944.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c5a0e84e955d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c5a6f432a1ec.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c5a9ebef1517.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c5ad60521f8c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c5b58cc992af.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c5ba9e455d5e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c639d837f5e4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c6a145742708.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c6a2975228af.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c6e1e9fbf39b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c6f5b5b5be41.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c755a0c4edcc.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c76664770c07.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c7c0470bcf87.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c7d0deb71576.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c7e827fc7f41.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c80f79579fed.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c85b79d70079.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c8d2d32f7f29.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c9485c38fdd5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c97472ef2c66.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c9d42d7534e0.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c9ea9d5eab65.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/c9f0dc2c8b43.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ca0f1a17c8e5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ca2b54b95ade.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ca30a97e9d13.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ca360bec5851.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cac80797770f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cae51154e1ce.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cb28adab4e8a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cb602182cde3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cb68fce07789.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cb75210abebe.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cbf0394039f8.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cc839823755b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ccea49708830.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cd29c88c9e36.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cd314653a4d8.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cd48cfab4e44.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cd5714db652d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ce207b69ff37.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ceb32a193eff.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ceb601fe8dba.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cec299c2a2d5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cf1b9d26d38d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cf603a9ef2d5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/cfdbaef73a8b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d0079cc188e9.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d0b132d2c7ec.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d10d315f123f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d10ef306996b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d144144a2f3f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d15ca3469b87.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d18f6431ebce.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d1a60c3b9fe5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d1afdb8cf70d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d1b279cc02ae.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d1f1ea894da1.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d25b8a8ad3c4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d26bb2ed6e71.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d27ac9e54901.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d28bd830c171.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d2c5fb82fe5f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d2fb715b0c41.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d30d079e6f9a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d332d7b8a26e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d3de0d313d61.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d3e884109b45.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d41b33fcb94f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d4583e9525dc.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d51b3fe0fa1b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d567a1a22d33.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d5a39339ff3d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d5c63a8d9e94.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d659d7fd5ccf.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d6803e467592.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d69698f838db.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d6b109c82067.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d6dbb0820ea5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d6f36ec5564a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d74ccc796517.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d774692d9919.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d7a01fca9838.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d7bc00091cfc.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d801c0a66738.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d83d0695e215.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d865997a6280.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d881c04f01fe.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d8cdb7d7283a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d93b61dc8f64.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d990a3f0cbdb.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d99b0f7dd9b9.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/d9ad2a0ec026.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/da0a83f074f3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/da2bdf4236ac.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/da44f80b422b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/da6bbb76d562.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/da9262d9f5d9.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/da949aa67a4f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/da9fe02dead3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/dad71ba27a9b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/dbee04ae6426.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/dbfd238b3468.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/dc0eea0b68a7.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/dc0f6e5b489b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/dccdf750c962.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/dce73d90c00c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/dd3176bacfe2.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/dd3dad6ca78f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/dd90c321d7bc.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ddb222ff7c1d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/dde43aa22ae6.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/de4cdabbce6d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/de730033c683.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/de778495a1cd.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/dea7538bb91a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/dec5595e6154.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/df4913ca3712.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/df8365d6ac33.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/df84e7113003.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e037643244b7.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e03e70bc8bba.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e04f3c6619a3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e06cccc08c59.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e087bd4b88f2.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e12df54e0d1e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e12f9f19d1be.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e135d7ba9a0e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e17507a4a1f5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e19936582c61.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e1e490773462.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e1fb532f55df.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e2161692a0b4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e23add229074.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e25ccfe38e44.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e29e54ff921e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e2a47a74e6e1.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e2c39ed0c941.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e2c3b037413b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e32a359be36d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e32dc722eca5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e34fa07bd64d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e39b627cf648.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e3b47ed5b511.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e3cd96cb094c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e3e490babc0c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e3ec668f6fad.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e4210e7fe587.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e4b0df29b96f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e4d3d437b0a8.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e4f12411fd85.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e5197d77ec68.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e540d2e35d15.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e599151ca14b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e5d56f4f359b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e5de79795c1d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e60e4edb3ca9.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e62490b7d0e9.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e632e38fd2d4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e6552b7432b3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e663c6627a95.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e66855a5c583.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e68746d426b2.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e68bdd36e589.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e6f0ce5bf282.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e740af6ac6ea.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e756495c11cb.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e76a9cbb2a8c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e77a93c3d9a9.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e7a372a1c3a4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e7b5dd5bab1f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e811f39a1243.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e821c1b6417a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e868c3da340b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e893e86dde94.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e9129ce55fd7.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e9286ddf6ffe.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e9678824215d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e96bd80a8a53.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/e9ff9352ccb3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ea1d045f9fea.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ea588d1e5d96.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ea68b58a6e8f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ea7e21bab610.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ea9c41e1ced0.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/eabc7c716255.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/eadfc8809ec8.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/eb1ad14dd281.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/eb1d37b71fd1.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/eb32a815f78c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ec0c9f817b03.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ec4649213ccf.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ecb4500285ed.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ed2c52c14493.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ed2ef440d22c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ed648b9bcd95.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ed6704e3b72e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ee2c2a5f7d0e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ee36ca728641.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ee3fe7809e6a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ee74c3b177e0.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/eeb231c3ef1f.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/eebd1e195952.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ef476be214d4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ef5155990874.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ef7eb85b75fc.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ef8109305128.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ef99c499d665.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f00ce9b9d6f4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f02057c41256.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f0267c42907c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f02956bd7c50.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f06e7a9df795.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f080a22008be.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f0860c21533b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f0a2dc580009.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f2094a20b275.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f233638e0e90.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f2d2a0c92034.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f2f569a64949.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f30f203ef51e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f3a4751af42e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f42b693a9414.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f451eee2b66b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f45f1485c940.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f48241b0c995.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f4de9620e3f2.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f549294e12e1.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f55e1d2a19e4.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f57cf3b6f48e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f580566e27f5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f583a722434c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f58cdfa968be.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f58d37d48e42.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f58f0b2fd718.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f5e9a307288c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f64214bed40e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f69400b316a7.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f69835dc7c50.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f6f3ea0d2693.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f71333204618.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f71aca5a7dc3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f7defe70afc3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f7fec8935126.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f8372e80f731.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f85c78201a50.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f8d62557ad0c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f8f5942b690e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f8fc411092c7.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f901d460517c.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f9156aeffc5e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f952ad2e4356.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f999c6921e6d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f9d8ff3e6592.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/f9e1c439d4c8.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fa0c87bd75ce.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fa3e544a7401.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fa59221cf464.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fa6f3d8bb1d5.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fa9bece586fc.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fb1b8771c70a.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fb61230b99dd.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fb6b8200b7f8.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fb88d23fc5fe.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fbcbc81cf9be.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fc1b1841eadf.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fc603cbedb41.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fcc32dffd24d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fcc6aa6755e6.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fce73678f650.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fd62bd0db4f1.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fd87b6b2e664.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fe37f4492920.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fe3f62695b2d.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/fecf4c5ae84b.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ff344e5c9341.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ff4832d55461.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ff52392372d3.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ff631653374e.jpg  \n",
            "  inflating: glacomadataset2/not_glaucoma/ff8a0b45c789.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHjMUbbrGUMv"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import pandocfilters as f\n",
        " \n",
        "import os\n",
        "import cv2\n",
        "from google.colab import files\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from termcolor import colored\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihOrnAj0wJDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0248b604-d56d-431f-cfe8-7167f1ef402c"
      },
      "source": [
        "print(os.listdir(\"/content/glacomadataset2\"))\n",
        "train_transforms = transforms.Compose([transforms.Resize(size=(224,224)),\n",
        "                                       transforms.ToTensor()])\n",
        "validation_transforms = transforms.Compose([transforms.Resize(size=(224,224)),\n",
        "                                            transforms.ToTensor()\n",
        "                                            ])\n",
        "img_dir = '/content/glacomadataset2'\n",
        "train_data = datasets.ImageFolder(img_dir, transform=train_transforms)\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2\n",
        "test_size = 0.1\n",
        " \n",
        "# convert data to a normalized torch.FloatTensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "valid_split = int(np.floor((valid_size) * num_train))\n",
        "test_split = int(np.floor((valid_size + test_size) * num_train))\n",
        "valid_idx, test_idx, train_idx = indices[:valid_split], indices[valid_split:test_split], indices[test_split:]\n",
        " \n",
        "print(len(valid_idx), len(test_idx), len(train_idx))\n",
        " \n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        " \n",
        "# prepare data loaders (combine dataset and sampler)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=20,\n",
        "                                           sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=20,\n",
        "                                           sampler=valid_sampler, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(train_data, batch_size=20,\n",
        "                                          sampler=test_sampler, num_workers=num_workers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['not_glaucoma', 'glaucoma']\n",
            "194 97 680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTcLvQyFCLQW"
      },
      "source": [
        "torch.save(train_loader, '/content/drive/MyDrive/glacoma1trainloader2.pth')\n",
        "torch.save(valid_loader, '/content/drive/MyDrive/glacoma1validloader2.pth')\n",
        "torch.save(test_loader, '/content/drive/MyDrive/glacoma1testloader2.pth')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S08xsXmCWpon"
      },
      "source": [
        "train_loader=torch.load('/content/drive/MyDrive/glacoma1trainloader2.pth')\n",
        "valid_loader=torch.load('/content/drive/MyDrive/glacoma1validloader2.pth')\n",
        "test_loader=torch.load('/content/drive/MyDrive/glacoma1testloader2.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9sRZCnE2XTC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-3OM4c1_H88"
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "#12 30\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        " \n",
        " \n",
        "num_ftrs=model.fc.in_features\n",
        " \n",
        "#model.classifier[1]=nn.Conv2d(512,2,kernel_size=(1,1), stride=(1,1))\n",
        " \n",
        "model.fc= nn.Linear(num_ftrs, 2)\n",
        " \n",
        "fc_parameters = model.fc.parameters()\n",
        "for param in fc_parameters:\n",
        "    param.requires_grad = True\n",
        " \n",
        "model\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.001,momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRwPPjjC2IwU",
        "outputId": "782d6acd-5d44-4d1c-e592-b36c3195a283"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMAo23qu_Nek"
      },
      "source": [
        "def train_accuracy(model, criterion, use_cuda):\n",
        "    # monitor test loss and accuracy\n",
        "    #train_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        " \n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss\n",
        "        #train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "        train_accuracy=100. * correct / total\n",
        "    print('\\ntrain Accuracy: %2.2f%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "    return train_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlj0jb1dDkTw"
      },
      "source": [
        " \n",
        "def valid_accuracy(model, criterion, use_cuda):\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "   \n",
        "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "       \n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "        test_accuracy=100. * correct / total\n",
        "    print('\\n validation Accuracy: %2.2f%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "   \n",
        "   \n",
        "    return test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlS_Uf2QTfmt"
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        " \n",
        " \n",
        "def test(model, criterion, use_cuda):\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    pre=0.0\n",
        "    count=0\n",
        "    rec=0.0\n",
        "    f1_m=0.0\n",
        "    au=0.0\n",
        "    y_pred=[]\n",
        "    y_target=[]\n",
        " \n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss\n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        y_pred_list = torch.tensor([a.squeeze().tolist() for a in pred])\n",
        "        targetlist =torch.tensor([t.squeeze().tolist() for t in target])\n",
        "       \n",
        "        y_pred.append(y_pred_list)\n",
        "        y_target.append(targetlist)\n",
        "        #y_target = torch.stack(target,1) \n",
        "        \n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "        test_accuracy=100. * correct / total\n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "    print('\\nTest Accuracy: %2.5f%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "    y_pred_list = torch.cat(y_pred)\n",
        "    targetlist = torch.cat(y_target)\n",
        "    y_predd=y_pred_list.numpy()\n",
        "    targett=targetlist.numpy()\n",
        "    aucc=recall_score(targett, y_predd, average='macro')\n",
        "   \n",
        "    \n",
        "    rec=recall_score(targett, y_predd, average='macro')\n",
        "    pre =precision_score(targett, y_predd, average='macro')\n",
        "    f_m=f1_score(targett, y_predd, average='macro')\n",
        " \n",
        "    #auu=float(au/count)\n",
        "    print(\"Precision=\"+str(pre))\n",
        "    print(\"Recall=\"+str(rec))\n",
        "    print(\"F1=\"+str(f_m))\n",
        "    return test_accuracy\n",
        " \n",
        "# %%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHTfVqktFld_"
      },
      "source": [
        "def train(n_epochs, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        " \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        " \n",
        "            # initialize weights to zero\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            \n",
        "            # calculate loss\n",
        "            loss = criterion(output, target)\n",
        " \n",
        "            # back prop\n",
        "            loss.backward()\n",
        "                      # grad\n",
        "            optimizer.step()\n",
        " \n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        " \n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Epoch %d, Batch %d loss: %.6f' %\n",
        "                      (epoch, batch_idx + 1, train_loss))\n",
        " \n",
        "        ######################\n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        " \n",
        "        # print training/validation statistics\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch,\n",
        "            train_loss,\n",
        "            valid_loss\n",
        "        ))\n",
        "        \n",
        "       \n",
        "       \n",
        "  \n",
        "        \n",
        "        \n",
        " \n",
        "        #test(model, criterion, use_cuda)\n",
        "        \n",
        "        tra_ac = train_accuracy(model, criterion, use_cuda)\n",
        "        val_acc = valid_accuracy(model, criterion, use_cuda)\n",
        "     \n",
        "        \n",
        "\n",
        "        if valid_loss < valid_loss_min:\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "                valid_loss_min,\n",
        "                valid_loss))\n",
        "            valid_loss_min = valid_loss\n",
        "    \n",
        "   \n",
        "\n",
        " \n",
        "    return model\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTs7VdjfE3vx",
        "outputId": "aecf6a0e-47f6-4b05-fe8d-aca38c3a5f1a"
      },
      "source": [
        "train(25, model, optimizer, criterion, use_cuda, 'resnet18.pt')\n",
        "model.load_state_dict(torch.load('resnet18.pt'))\n",
        "test(model, criterion, use_cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 1 loss: 0.735106\n",
            "Epoch: 1 \tTraining Loss: 0.497804 \tValidation Loss: 0.346919\n",
            "\n",
            "train Accuracy: 89.85% (611/680)\n",
            "\n",
            " validation Accuracy: 87.11% (169/194)\n",
            "Validation loss decreased (inf --> 0.346919).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 0.197509\n",
            "Epoch: 2 \tTraining Loss: 0.267360 \tValidation Loss: 0.225269\n",
            "\n",
            "train Accuracy: 94.85% (645/680)\n",
            "\n",
            " validation Accuracy: 93.30% (181/194)\n",
            "Validation loss decreased (0.346919 --> 0.225269).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 0.260514\n",
            "Epoch: 3 \tTraining Loss: 0.228230 \tValidation Loss: 0.188875\n",
            "\n",
            "train Accuracy: 95.74% (651/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Validation loss decreased (0.225269 --> 0.188875).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 0.129081\n",
            "Epoch: 4 \tTraining Loss: 0.162980 \tValidation Loss: 0.159343\n",
            "\n",
            "train Accuracy: 97.50% (663/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Validation loss decreased (0.188875 --> 0.159343).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 0.075706\n",
            "Epoch: 5 \tTraining Loss: 0.157741 \tValidation Loss: 0.187894\n",
            "\n",
            "train Accuracy: 96.03% (653/680)\n",
            "\n",
            " validation Accuracy: 94.85% (184/194)\n",
            "Epoch 6, Batch 1 loss: 0.100832\n",
            "Epoch: 6 \tTraining Loss: 0.144980 \tValidation Loss: 0.152151\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Validation loss decreased (0.159343 --> 0.152151).  Saving model ...\n",
            "Epoch 7, Batch 1 loss: 0.096293\n",
            "Epoch: 7 \tTraining Loss: 0.114512 \tValidation Loss: 0.127088\n",
            "\n",
            "train Accuracy: 98.38% (669/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Validation loss decreased (0.152151 --> 0.127088).  Saving model ...\n",
            "Epoch 8, Batch 1 loss: 0.068945\n",
            "Epoch: 8 \tTraining Loss: 0.119796 \tValidation Loss: 0.117006\n",
            "\n",
            "train Accuracy: 98.09% (667/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.127088 --> 0.117006).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 0.140530\n",
            "Epoch: 9 \tTraining Loss: 0.114898 \tValidation Loss: 0.114513\n",
            "\n",
            "train Accuracy: 98.68% (671/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Validation loss decreased (0.117006 --> 0.114513).  Saving model ...\n",
            "Epoch 10, Batch 1 loss: 0.237749\n",
            "Epoch: 10 \tTraining Loss: 0.144074 \tValidation Loss: 0.133315\n",
            "\n",
            "train Accuracy: 97.35% (662/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Epoch 11, Batch 1 loss: 0.033936\n",
            "Epoch: 11 \tTraining Loss: 0.123404 \tValidation Loss: 0.102766\n",
            "\n",
            "train Accuracy: 99.12% (674/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Validation loss decreased (0.114513 --> 0.102766).  Saving model ...\n",
            "Epoch 12, Batch 1 loss: 0.112764\n",
            "Epoch: 12 \tTraining Loss: 0.104292 \tValidation Loss: 0.105290\n",
            "\n",
            "train Accuracy: 99.12% (674/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Epoch 13, Batch 1 loss: 0.042653\n",
            "Epoch: 13 \tTraining Loss: 0.099311 \tValidation Loss: 0.098184\n",
            "\n",
            "train Accuracy: 99.12% (674/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Validation loss decreased (0.102766 --> 0.098184).  Saving model ...\n",
            "Epoch 14, Batch 1 loss: 0.170719\n",
            "Epoch: 14 \tTraining Loss: 0.097921 \tValidation Loss: 0.099374\n",
            "\n",
            "train Accuracy: 98.97% (673/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Epoch 15, Batch 1 loss: 0.056591\n",
            "Epoch: 15 \tTraining Loss: 0.081319 \tValidation Loss: 0.120360\n",
            "\n",
            "train Accuracy: 97.94% (666/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 16, Batch 1 loss: 0.036932\n",
            "Epoch: 16 \tTraining Loss: 0.081286 \tValidation Loss: 0.105146\n",
            "\n",
            "train Accuracy: 99.26% (675/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Epoch 17, Batch 1 loss: 0.066944\n",
            "Epoch: 17 \tTraining Loss: 0.099874 \tValidation Loss: 0.099538\n",
            "\n",
            "train Accuracy: 99.26% (675/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Epoch 18, Batch 1 loss: 0.100511\n",
            "Epoch: 18 \tTraining Loss: 0.097618 \tValidation Loss: 0.092707\n",
            "\n",
            "train Accuracy: 98.97% (673/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Validation loss decreased (0.098184 --> 0.092707).  Saving model ...\n",
            "Epoch 19, Batch 1 loss: 0.057140\n",
            "Epoch: 19 \tTraining Loss: 0.079046 \tValidation Loss: 0.093366\n",
            "\n",
            "train Accuracy: 99.12% (674/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Epoch 20, Batch 1 loss: 0.111630\n",
            "Epoch: 20 \tTraining Loss: 0.075664 \tValidation Loss: 0.100137\n",
            "\n",
            "train Accuracy: 99.12% (674/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Epoch 21, Batch 1 loss: 0.047448\n",
            "Epoch: 21 \tTraining Loss: 0.079304 \tValidation Loss: 0.089576\n",
            "\n",
            "train Accuracy: 99.56% (677/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Validation loss decreased (0.092707 --> 0.089576).  Saving model ...\n",
            "Epoch 22, Batch 1 loss: 0.038788\n",
            "Epoch: 22 \tTraining Loss: 0.074479 \tValidation Loss: 0.124462\n",
            "\n",
            "train Accuracy: 98.53% (670/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Epoch 23, Batch 1 loss: 0.021550\n",
            "Epoch: 23 \tTraining Loss: 0.092490 \tValidation Loss: 0.083775\n",
            "\n",
            "train Accuracy: 99.56% (677/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Validation loss decreased (0.089576 --> 0.083775).  Saving model ...\n",
            "Epoch 24, Batch 1 loss: 0.016674\n",
            "Epoch: 24 \tTraining Loss: 0.075816 \tValidation Loss: 0.089455\n",
            "\n",
            "train Accuracy: 99.56% (677/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Epoch 25, Batch 1 loss: 0.043778\n",
            "Epoch: 25 \tTraining Loss: 0.057694 \tValidation Loss: 0.076212\n",
            "\n",
            "train Accuracy: 99.56% (677/680)\n",
            "\n",
            " validation Accuracy: 98.45% (191/194)\n",
            "Validation loss decreased (0.083775 --> 0.076212).  Saving model ...\n",
            "Test Loss: 0.085136\n",
            "\n",
            "\n",
            "Test Accuracy: 96.90722% (94/97)\n",
            "Precision=0.9754098360655737\n",
            "Recall=0.9615384615384616\n",
            "F1=0.9673949579831933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.90721649484536"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNg0BZCvPy5q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2AOXEcTjRJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664d352b-928c-4dac-bc51-9ebd7b1b1836"
      },
      "source": [
        "model = models.resnet50(pretrained=True)\n",
        "#12 30\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "num_ftrs=model.fc.in_features\n",
        "\n",
        "#model.classifier[1]=nn.Conv2d(512,2,kernel_size=(1,1), stride=(1,1))\n",
        "\n",
        "model.fc= nn.Linear(num_ftrs, 2)\n",
        "\n",
        "fc_parameters = model.fc.parameters()\n",
        "for param in fc_parameters:\n",
        "    param.requires_grad = True\n",
        "\n",
        "model\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "train(25, model, optimizer, criterion, use_cuda, 'resnet50.pt')\n",
        "model.load_state_dict(torch.load('resnet50.pt'))\n",
        "test(model, criterion, use_cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 1 loss: 0.704523\n",
            "Epoch: 1 \tTraining Loss: 0.507096 \tValidation Loss: 0.401308\n",
            "\n",
            "train Accuracy: 89.26% (607/680)\n",
            "\n",
            " validation Accuracy: 89.18% (173/194)\n",
            "Validation loss decreased (inf --> 0.401308).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 0.219177\n",
            "Epoch: 2 \tTraining Loss: 0.272071 \tValidation Loss: 0.224146\n",
            "\n",
            "train Accuracy: 94.71% (644/680)\n",
            "\n",
            " validation Accuracy: 92.27% (179/194)\n",
            "Validation loss decreased (0.401308 --> 0.224146).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 0.476140\n",
            "Epoch: 3 \tTraining Loss: 0.214953 \tValidation Loss: 0.193667\n",
            "\n",
            "train Accuracy: 95.59% (650/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Validation loss decreased (0.224146 --> 0.193667).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 0.133328\n",
            "Epoch: 4 \tTraining Loss: 0.177163 \tValidation Loss: 0.210722\n",
            "\n",
            "train Accuracy: 95.74% (651/680)\n",
            "\n",
            " validation Accuracy: 92.78% (180/194)\n",
            "Epoch 5, Batch 1 loss: 0.407887\n",
            "Epoch: 5 \tTraining Loss: 0.177511 \tValidation Loss: 0.159367\n",
            "\n",
            "train Accuracy: 96.62% (657/680)\n",
            "\n",
            " validation Accuracy: 94.85% (184/194)\n",
            "Validation loss decreased (0.193667 --> 0.159367).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 0.051656\n",
            "Epoch: 6 \tTraining Loss: 0.176169 \tValidation Loss: 0.159359\n",
            "\n",
            "train Accuracy: 97.35% (662/680)\n",
            "\n",
            " validation Accuracy: 94.85% (184/194)\n",
            "Validation loss decreased (0.159367 --> 0.159359).  Saving model ...\n",
            "Epoch 7, Batch 1 loss: 0.428199\n",
            "Epoch: 7 \tTraining Loss: 0.146700 \tValidation Loss: 0.142915\n",
            "\n",
            "train Accuracy: 96.62% (657/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Validation loss decreased (0.159359 --> 0.142915).  Saving model ...\n",
            "Epoch 8, Batch 1 loss: 0.279332\n",
            "Epoch: 8 \tTraining Loss: 0.131929 \tValidation Loss: 0.133778\n",
            "\n",
            "train Accuracy: 97.21% (661/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Validation loss decreased (0.142915 --> 0.133778).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 0.236931\n",
            "Epoch: 9 \tTraining Loss: 0.113765 \tValidation Loss: 0.135577\n",
            "\n",
            "train Accuracy: 97.79% (665/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Epoch 10, Batch 1 loss: 0.111115\n",
            "Epoch: 10 \tTraining Loss: 0.119580 \tValidation Loss: 0.124625\n",
            "\n",
            "train Accuracy: 97.65% (664/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.133778 --> 0.124625).  Saving model ...\n",
            "Epoch 11, Batch 1 loss: 0.047195\n",
            "Epoch: 11 \tTraining Loss: 0.123193 \tValidation Loss: 0.177421\n",
            "\n",
            "train Accuracy: 96.62% (657/680)\n",
            "\n",
            " validation Accuracy: 92.78% (180/194)\n",
            "Epoch 12, Batch 1 loss: 0.078122\n",
            "Epoch: 12 \tTraining Loss: 0.152574 \tValidation Loss: 0.114521\n",
            "\n",
            "train Accuracy: 97.94% (666/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.124625 --> 0.114521).  Saving model ...\n",
            "Epoch 13, Batch 1 loss: 0.051594\n",
            "Epoch: 13 \tTraining Loss: 0.120839 \tValidation Loss: 0.140500\n",
            "\n",
            "train Accuracy: 98.09% (667/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Epoch 14, Batch 1 loss: 0.110212\n",
            "Epoch: 14 \tTraining Loss: 0.104493 \tValidation Loss: 0.132814\n",
            "\n",
            "train Accuracy: 98.53% (670/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Epoch 15, Batch 1 loss: 0.069404\n",
            "Epoch: 15 \tTraining Loss: 0.094560 \tValidation Loss: 0.115839\n",
            "\n",
            "train Accuracy: 98.24% (668/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Epoch 16, Batch 1 loss: 0.042212\n",
            "Epoch: 16 \tTraining Loss: 0.107296 \tValidation Loss: 0.125961\n",
            "\n",
            "train Accuracy: 98.82% (672/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Epoch 17, Batch 1 loss: 0.114009\n",
            "Epoch: 17 \tTraining Loss: 0.118531 \tValidation Loss: 0.111427\n",
            "\n",
            "train Accuracy: 98.68% (671/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Validation loss decreased (0.114521 --> 0.111427).  Saving model ...\n",
            "Epoch 18, Batch 1 loss: 0.047695\n",
            "Epoch: 18 \tTraining Loss: 0.087197 \tValidation Loss: 0.105154\n",
            "\n",
            "train Accuracy: 98.82% (672/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Validation loss decreased (0.111427 --> 0.105154).  Saving model ...\n",
            "Epoch 19, Batch 1 loss: 0.142824\n",
            "Epoch: 19 \tTraining Loss: 0.089297 \tValidation Loss: 0.111214\n",
            "\n",
            "train Accuracy: 98.82% (672/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Epoch 20, Batch 1 loss: 0.126900\n",
            "Epoch: 20 \tTraining Loss: 0.112018 \tValidation Loss: 0.095797\n",
            "\n",
            "train Accuracy: 99.26% (675/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.105154 --> 0.095797).  Saving model ...\n",
            "Epoch 21, Batch 1 loss: 0.121978\n",
            "Epoch: 21 \tTraining Loss: 0.089420 \tValidation Loss: 0.099613\n",
            "\n",
            "train Accuracy: 99.12% (674/680)\n",
            "\n",
            " validation Accuracy: 97.94% (190/194)\n",
            "Epoch 22, Batch 1 loss: 0.060487\n",
            "Epoch: 22 \tTraining Loss: 0.101439 \tValidation Loss: 0.094657\n",
            "\n",
            "train Accuracy: 99.12% (674/680)\n",
            "\n",
            " validation Accuracy: 97.94% (190/194)\n",
            "Validation loss decreased (0.095797 --> 0.094657).  Saving model ...\n",
            "Epoch 23, Batch 1 loss: 0.061550\n",
            "Epoch: 23 \tTraining Loss: 0.113180 \tValidation Loss: 0.110285\n",
            "\n",
            "train Accuracy: 99.26% (675/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 24, Batch 1 loss: 0.069661\n",
            "Epoch: 24 \tTraining Loss: 0.082117 \tValidation Loss: 0.093169\n",
            "\n",
            "train Accuracy: 99.56% (677/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Validation loss decreased (0.094657 --> 0.093169).  Saving model ...\n",
            "Epoch 25, Batch 1 loss: 0.174922\n",
            "Epoch: 25 \tTraining Loss: 0.067528 \tValidation Loss: 0.089456\n",
            "\n",
            "train Accuracy: 99.41% (676/680)\n",
            "\n",
            " validation Accuracy: 97.94% (190/194)\n",
            "Validation loss decreased (0.093169 --> 0.089456).  Saving model ...\n",
            "Test Loss: 0.093436\n",
            "\n",
            "\n",
            "Test Accuracy: 98.96907% (96/97)\n",
            "Precision=0.9875\n",
            "Recall=0.9913793103448276\n",
            "F1=0.9893230599889928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.96907216494846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef8mMeaWOFJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f5243a-7cc8-4a56-8d25-5034d33feeb8"
      },
      "source": [
        "model = models.resnet101(pretrained=True)\n",
        "#12 30\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "num_ftrs=model.fc.in_features\n",
        "\n",
        "#model.classifier[1]=nn.Conv2d(512,2,kernel_size=(1,1), stride=(1,1))\n",
        "\n",
        "model.fc= nn.Linear(num_ftrs, 2)\n",
        "\n",
        "fc_parameters = model.fc.parameters()\n",
        "for param in fc_parameters:\n",
        "    param.requires_grad = True\n",
        "\n",
        "model\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.001,momentum=0.9)\n",
        "train(25, model, optimizer, criterion, use_cuda, 'resnet101.pt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 1 loss: 0.670438\n",
            "Epoch: 1 \tTraining Loss: 0.505257 \tValidation Loss: 0.355589\n",
            "\n",
            "train Accuracy: 89.56% (609/680)\n",
            "\n",
            " validation Accuracy: 88.14% (171/194)\n",
            "Validation loss decreased (inf --> 0.355589).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 0.277255\n",
            "Epoch: 2 \tTraining Loss: 0.241098 \tValidation Loss: 0.219495\n",
            "\n",
            "train Accuracy: 94.56% (643/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Validation loss decreased (0.355589 --> 0.219495).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 0.237943\n",
            "Epoch: 3 \tTraining Loss: 0.185726 \tValidation Loss: 0.184971\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 92.27% (179/194)\n",
            "Validation loss decreased (0.219495 --> 0.184971).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 0.158490\n",
            "Epoch: 4 \tTraining Loss: 0.159799 \tValidation Loss: 0.177405\n",
            "\n",
            "train Accuracy: 96.76% (658/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Validation loss decreased (0.184971 --> 0.177405).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 0.161717\n",
            "Epoch: 5 \tTraining Loss: 0.140337 \tValidation Loss: 0.165657\n",
            "\n",
            "train Accuracy: 96.91% (659/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Validation loss decreased (0.177405 --> 0.165657).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 0.062841\n",
            "Epoch: 6 \tTraining Loss: 0.148553 \tValidation Loss: 0.171635\n",
            "\n",
            "train Accuracy: 96.76% (658/680)\n",
            "\n",
            " validation Accuracy: 92.78% (180/194)\n",
            "Epoch 7, Batch 1 loss: 0.063620\n",
            "Epoch: 7 \tTraining Loss: 0.128232 \tValidation Loss: 0.170150\n",
            "\n",
            "train Accuracy: 97.21% (661/680)\n",
            "\n",
            " validation Accuracy: 93.30% (181/194)\n",
            "Epoch 8, Batch 1 loss: 0.088132\n",
            "Epoch: 8 \tTraining Loss: 0.130885 \tValidation Loss: 0.180614\n",
            "\n",
            "train Accuracy: 97.35% (662/680)\n",
            "\n",
            " validation Accuracy: 92.27% (179/194)\n",
            "Epoch 9, Batch 1 loss: 0.140124\n",
            "Epoch: 9 \tTraining Loss: 0.134601 \tValidation Loss: 0.154782\n",
            "\n",
            "train Accuracy: 97.79% (665/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Validation loss decreased (0.165657 --> 0.154782).  Saving model ...\n",
            "Epoch 10, Batch 1 loss: 0.083253\n",
            "Epoch: 10 \tTraining Loss: 0.127248 \tValidation Loss: 0.139545\n",
            "\n",
            "train Accuracy: 98.09% (667/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Validation loss decreased (0.154782 --> 0.139545).  Saving model ...\n",
            "Epoch 11, Batch 1 loss: 0.109299\n",
            "Epoch: 11 \tTraining Loss: 0.104704 \tValidation Loss: 0.164294\n",
            "\n",
            "train Accuracy: 97.65% (664/680)\n",
            "\n",
            " validation Accuracy: 92.78% (180/194)\n",
            "Epoch 12, Batch 1 loss: 0.230336\n",
            "Epoch: 12 \tTraining Loss: 0.126762 \tValidation Loss: 0.127940\n",
            "\n",
            "train Accuracy: 98.38% (669/680)\n",
            "\n",
            " validation Accuracy: 94.85% (184/194)\n",
            "Validation loss decreased (0.139545 --> 0.127940).  Saving model ...\n",
            "Epoch 13, Batch 1 loss: 0.053610\n",
            "Epoch: 13 \tTraining Loss: 0.100011 \tValidation Loss: 0.125891\n",
            "\n",
            "train Accuracy: 98.97% (673/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Validation loss decreased (0.127940 --> 0.125891).  Saving model ...\n",
            "Epoch 14, Batch 1 loss: 0.073130\n",
            "Epoch: 14 \tTraining Loss: 0.100718 \tValidation Loss: 0.127048\n",
            "\n",
            "train Accuracy: 98.53% (670/680)\n",
            "\n",
            " validation Accuracy: 94.85% (184/194)\n",
            "Epoch 15, Batch 1 loss: 0.051311\n",
            "Epoch: 15 \tTraining Loss: 0.106774 \tValidation Loss: 0.126030\n",
            "\n",
            "train Accuracy: 98.82% (672/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Epoch 16, Batch 1 loss: 0.107925\n",
            "Epoch: 16 \tTraining Loss: 0.108577 \tValidation Loss: 0.121541\n",
            "\n",
            "train Accuracy: 98.24% (668/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Validation loss decreased (0.125891 --> 0.121541).  Saving model ...\n",
            "Epoch 17, Batch 1 loss: 0.028314\n",
            "Epoch: 17 \tTraining Loss: 0.091026 \tValidation Loss: 0.119891\n",
            "\n",
            "train Accuracy: 98.68% (671/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Validation loss decreased (0.121541 --> 0.119891).  Saving model ...\n",
            "Epoch 18, Batch 1 loss: 0.137872\n",
            "Epoch: 18 \tTraining Loss: 0.090874 \tValidation Loss: 0.121635\n",
            "\n",
            "train Accuracy: 98.82% (672/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 19, Batch 1 loss: 0.129059\n",
            "Epoch: 19 \tTraining Loss: 0.095930 \tValidation Loss: 0.112995\n",
            "\n",
            "train Accuracy: 98.68% (671/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.119891 --> 0.112995).  Saving model ...\n",
            "Epoch 20, Batch 1 loss: 0.042712\n",
            "Epoch: 20 \tTraining Loss: 0.080332 \tValidation Loss: 0.113516\n",
            "\n",
            "train Accuracy: 98.97% (673/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Epoch 21, Batch 1 loss: 0.071926\n",
            "Epoch: 21 \tTraining Loss: 0.080682 \tValidation Loss: 0.114440\n",
            "\n",
            "train Accuracy: 98.97% (673/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Epoch 22, Batch 1 loss: 0.035229\n",
            "Epoch: 22 \tTraining Loss: 0.119110 \tValidation Loss: 0.128013\n",
            "\n",
            "train Accuracy: 98.24% (668/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Epoch 23, Batch 1 loss: 0.038571\n",
            "Epoch: 23 \tTraining Loss: 0.100210 \tValidation Loss: 0.132016\n",
            "\n",
            "train Accuracy: 98.09% (667/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Epoch 24, Batch 1 loss: 0.090313\n",
            "Epoch: 24 \tTraining Loss: 0.085813 \tValidation Loss: 0.109419\n",
            "\n",
            "train Accuracy: 98.97% (673/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.112995 --> 0.109419).  Saving model ...\n",
            "Epoch 25, Batch 1 loss: 0.018069\n",
            "Epoch: 25 \tTraining Loss: 0.081957 \tValidation Loss: 0.115094\n",
            "\n",
            "train Accuracy: 99.26% (675/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (16): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (17): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (18): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (19): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (20): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (21): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (22): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHmoSgNipM3c",
        "outputId": "0f263776-4f43-4c04-b927-c7cfd7b03a5b"
      },
      "source": [
        "model.load_state_dict(torch.load('resnet101.pt'))\n",
        "test(model, criterion, use_cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.049116\n",
            "\n",
            "\n",
            "Test Accuracy: 98.96907% (96/97)\n",
            "Precision=0.9915254237288136\n",
            "Recall=0.9871794871794872\n",
            "F1=0.9892329892329892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.96907216494846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3Lg6TTTCw36",
        "outputId": "eb7f2108-7894-414e-f939-0fd17c822864"
      },
      "source": [
        "model = models.resnet152(pretrained=True)\n",
        "#12 30\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        " \n",
        " \n",
        "num_ftrs=model.fc.in_features\n",
        " \n",
        "#model.classifier[1]=nn.Conv2d(512,2,kernel_size=(1,1), stride=(1,1))\n",
        " \n",
        "model.fc= nn.Linear(num_ftrs, 2)\n",
        " \n",
        "fc_parameters = model.fc.parameters()\n",
        "for param in fc_parameters:\n",
        "    param.requires_grad = True\n",
        " \n",
        "model\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.001,momentum=0.9)\n",
        "train(25, model, optimizer, criterion, use_cuda, 'resnet152.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 1 loss: 0.717934\n",
            "Epoch: 1 \tTraining Loss: 0.484015 \tValidation Loss: 0.411393\n",
            "\n",
            "train Accuracy: 90.59% (616/680)\n",
            "\n",
            " validation Accuracy: 88.14% (171/194)\n",
            "Validation loss decreased (inf --> 0.411393).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 0.881498\n",
            "Epoch: 2 \tTraining Loss: 0.283713 \tValidation Loss: 0.269644\n",
            "\n",
            "train Accuracy: 93.24% (634/680)\n",
            "\n",
            " validation Accuracy: 89.69% (174/194)\n",
            "Validation loss decreased (0.411393 --> 0.269644).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 0.259476\n",
            "Epoch: 3 \tTraining Loss: 0.239944 \tValidation Loss: 0.204056\n",
            "\n",
            "train Accuracy: 93.53% (636/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Validation loss decreased (0.269644 --> 0.204056).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 0.118185\n",
            "Epoch: 4 \tTraining Loss: 0.158985 \tValidation Loss: 0.150294\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Validation loss decreased (0.204056 --> 0.150294).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 0.098647\n",
            "Epoch: 5 \tTraining Loss: 0.156312 \tValidation Loss: 0.136313\n",
            "\n",
            "train Accuracy: 97.65% (664/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Validation loss decreased (0.150294 --> 0.136313).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 0.100622\n",
            "Epoch: 6 \tTraining Loss: 0.149353 \tValidation Loss: 0.125178\n",
            "\n",
            "train Accuracy: 97.94% (666/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Validation loss decreased (0.136313 --> 0.125178).  Saving model ...\n",
            "Epoch 7, Batch 1 loss: 0.049224\n",
            "Epoch: 7 \tTraining Loss: 0.125446 \tValidation Loss: 0.112996\n",
            "\n",
            "train Accuracy: 97.79% (665/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Validation loss decreased (0.125178 --> 0.112996).  Saving model ...\n",
            "Epoch 8, Batch 1 loss: 0.137199\n",
            "Epoch: 8 \tTraining Loss: 0.117438 \tValidation Loss: 0.105633\n",
            "\n",
            "train Accuracy: 98.53% (670/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.112996 --> 0.105633).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 0.083055\n",
            "Epoch: 9 \tTraining Loss: 0.107407 \tValidation Loss: 0.098608\n",
            "\n",
            "train Accuracy: 98.38% (669/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.105633 --> 0.098608).  Saving model ...\n",
            "Epoch 10, Batch 1 loss: 0.031362\n",
            "Epoch: 10 \tTraining Loss: 0.106340 \tValidation Loss: 0.092885\n",
            "\n",
            "train Accuracy: 99.12% (674/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.098608 --> 0.092885).  Saving model ...\n",
            "Epoch 11, Batch 1 loss: 0.146552\n",
            "Epoch: 11 \tTraining Loss: 0.097758 \tValidation Loss: 0.094963\n",
            "\n",
            "train Accuracy: 98.68% (671/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Epoch 12, Batch 1 loss: 0.040090\n",
            "Epoch: 12 \tTraining Loss: 0.091747 \tValidation Loss: 0.089147\n",
            "\n",
            "train Accuracy: 99.26% (675/680)\n",
            "\n",
            " validation Accuracy: 97.94% (190/194)\n",
            "Validation loss decreased (0.092885 --> 0.089147).  Saving model ...\n",
            "Epoch 13, Batch 1 loss: 0.075160\n",
            "Epoch: 13 \tTraining Loss: 0.088553 \tValidation Loss: 0.082473\n",
            "\n",
            "train Accuracy: 99.26% (675/680)\n",
            "\n",
            " validation Accuracy: 98.97% (192/194)\n",
            "Validation loss decreased (0.089147 --> 0.082473).  Saving model ...\n",
            "Epoch 14, Batch 1 loss: 0.143149\n",
            "Epoch: 14 \tTraining Loss: 0.086290 \tValidation Loss: 0.086543\n",
            "\n",
            "train Accuracy: 99.26% (675/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Epoch 15, Batch 1 loss: 0.126753\n",
            "Epoch: 15 \tTraining Loss: 0.093319 \tValidation Loss: 0.082484\n",
            "\n",
            "train Accuracy: 99.41% (676/680)\n",
            "\n",
            " validation Accuracy: 97.94% (190/194)\n",
            "Epoch 16, Batch 1 loss: 0.034111\n",
            "Epoch: 16 \tTraining Loss: 0.089411 \tValidation Loss: 0.078967\n",
            "\n",
            "train Accuracy: 99.56% (677/680)\n",
            "\n",
            " validation Accuracy: 98.45% (191/194)\n",
            "Validation loss decreased (0.082473 --> 0.078967).  Saving model ...\n",
            "Epoch 17, Batch 1 loss: 0.039177\n",
            "Epoch: 17 \tTraining Loss: 0.065389 \tValidation Loss: 0.073723\n",
            "\n",
            "train Accuracy: 99.56% (677/680)\n",
            "\n",
            " validation Accuracy: 98.97% (192/194)\n",
            "Validation loss decreased (0.078967 --> 0.073723).  Saving model ...\n",
            "Epoch 18, Batch 1 loss: 0.141053\n",
            "Epoch: 18 \tTraining Loss: 0.077453 \tValidation Loss: 0.075071\n",
            "\n",
            "train Accuracy: 99.56% (677/680)\n",
            "\n",
            " validation Accuracy: 98.97% (192/194)\n",
            "Epoch 19, Batch 1 loss: 0.082115\n",
            "Epoch: 19 \tTraining Loss: 0.076532 \tValidation Loss: 0.072171\n",
            "\n",
            "train Accuracy: 99.56% (677/680)\n",
            "\n",
            " validation Accuracy: 98.45% (191/194)\n",
            "Validation loss decreased (0.073723 --> 0.072171).  Saving model ...\n",
            "Epoch 20, Batch 1 loss: 0.032850\n",
            "Epoch: 20 \tTraining Loss: 0.075852 \tValidation Loss: 0.071733\n",
            "\n",
            "train Accuracy: 99.41% (676/680)\n",
            "\n",
            " validation Accuracy: 98.97% (192/194)\n",
            "Validation loss decreased (0.072171 --> 0.071733).  Saving model ...\n",
            "Epoch 21, Batch 1 loss: 0.022941\n",
            "Epoch: 21 \tTraining Loss: 0.063436 \tValidation Loss: 0.068894\n",
            "\n",
            "train Accuracy: 99.56% (677/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Validation loss decreased (0.071733 --> 0.068894).  Saving model ...\n",
            "Epoch 22, Batch 1 loss: 0.033969\n",
            "Epoch: 22 \tTraining Loss: 0.072008 \tValidation Loss: 0.077544\n",
            "\n",
            "train Accuracy: 99.41% (676/680)\n",
            "\n",
            " validation Accuracy: 98.45% (191/194)\n",
            "Epoch 23, Batch 1 loss: 0.029199\n",
            "Epoch: 23 \tTraining Loss: 0.066114 \tValidation Loss: 0.068857\n",
            "\n",
            "train Accuracy: 99.85% (679/680)\n",
            "\n",
            " validation Accuracy: 97.94% (190/194)\n",
            "Validation loss decreased (0.068894 --> 0.068857).  Saving model ...\n",
            "Epoch 24, Batch 1 loss: 0.043100\n",
            "Epoch: 24 \tTraining Loss: 0.079191 \tValidation Loss: 0.071499\n",
            "\n",
            "train Accuracy: 99.56% (677/680)\n",
            "\n",
            " validation Accuracy: 97.94% (190/194)\n",
            "Epoch 25, Batch 1 loss: 0.026815\n",
            "Epoch: 25 \tTraining Loss: 0.076822 \tValidation Loss: 0.065753\n",
            "\n",
            "train Accuracy: 99.56% (677/680)\n",
            "\n",
            " validation Accuracy: 97.94% (190/194)\n",
            "Validation loss decreased (0.068857 --> 0.065753).  Saving model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (12): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (13): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (14): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (15): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (16): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (17): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (18): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (19): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (20): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (21): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (22): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (23): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (24): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (25): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (26): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (27): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (28): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (29): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (30): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (31): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (32): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (33): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (34): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (35): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EYJjU-wyfgF",
        "outputId": "ce7e1a91-0ab6-424b-8c5f-0c9a39b203f4"
      },
      "source": [
        "model.load_state_dict(torch.load('resnet152.pt'))\n",
        "test(model, criterion, use_cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.055729\n",
            "\n",
            "\n",
            "Test Accuracy: 98.96907% (96/97)\n",
            "Precision=0.9915254237288136\n",
            "Recall=0.9871794871794872\n",
            "F1=0.9892329892329892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.96907216494846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NCIOpsdi8hV",
        "outputId": "8bb340f1-2207-49fb-f951-42edf4574476"
      },
      "source": [
        "model = models.alexnet(pretrained=True)\n",
        "#12 30\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "num_ftrs=model.classifier[6].in_features\n",
        "\n",
        "#model.classifier[1]=nn.Conv2d(512,2,kernel_size=(1,1), stride=(1,1))\n",
        "\n",
        "model.classifier[6]= nn.Linear(num_ftrs, 2)\n",
        "\n",
        "fc_parameters = model.classifier[6].parameters()\n",
        "for param in fc_parameters:\n",
        "    param.requires_grad = True\n",
        "\n",
        "model\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.classifier[6].parameters(), lr=0.001,momentum=0.9)\n",
        "train(25, model, optimizer, criterion, use_cuda, 'alexnet.pt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 1 loss: 1.279488\n",
            "Epoch: 1 \tTraining Loss: 0.474686 \tValidation Loss: 0.231276\n",
            "\n",
            "train Accuracy: 93.53% (636/680)\n",
            "\n",
            " validation Accuracy: 91.24% (177/194)\n",
            "Validation loss decreased (inf --> 0.231276).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 0.133687\n",
            "Epoch: 2 \tTraining Loss: 0.350779 \tValidation Loss: 0.165906\n",
            "\n",
            "train Accuracy: 95.59% (650/680)\n",
            "\n",
            " validation Accuracy: 93.30% (181/194)\n",
            "Validation loss decreased (0.231276 --> 0.165906).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 0.151756\n",
            "Epoch: 3 \tTraining Loss: 0.194952 \tValidation Loss: 0.154389\n",
            "\n",
            "train Accuracy: 96.47% (656/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Validation loss decreased (0.165906 --> 0.154389).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 0.030456\n",
            "Epoch: 4 \tTraining Loss: 0.174247 \tValidation Loss: 0.114885\n",
            "\n",
            "train Accuracy: 96.91% (659/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Validation loss decreased (0.154389 --> 0.114885).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 0.182820\n",
            "Epoch: 5 \tTraining Loss: 0.149771 \tValidation Loss: 0.147360\n",
            "\n",
            "train Accuracy: 94.41% (642/680)\n",
            "\n",
            " validation Accuracy: 94.85% (184/194)\n",
            "Epoch 6, Batch 1 loss: 0.377941\n",
            "Epoch: 6 \tTraining Loss: 0.154247 \tValidation Loss: 0.108898\n",
            "\n",
            "train Accuracy: 98.24% (668/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Validation loss decreased (0.114885 --> 0.108898).  Saving model ...\n",
            "Epoch 7, Batch 1 loss: 0.076714\n",
            "Epoch: 7 \tTraining Loss: 0.146064 \tValidation Loss: 0.128709\n",
            "\n",
            "train Accuracy: 96.32% (655/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Epoch 8, Batch 1 loss: 0.079166\n",
            "Epoch: 8 \tTraining Loss: 0.157571 \tValidation Loss: 0.106953\n",
            "\n",
            "train Accuracy: 96.76% (658/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Validation loss decreased (0.108898 --> 0.106953).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 0.065908\n",
            "Epoch: 9 \tTraining Loss: 0.143199 \tValidation Loss: 0.127993\n",
            "\n",
            "train Accuracy: 95.59% (650/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Epoch 10, Batch 1 loss: 0.107465\n",
            "Epoch: 10 \tTraining Loss: 0.123204 \tValidation Loss: 0.081569\n",
            "\n",
            "train Accuracy: 99.26% (675/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Validation loss decreased (0.106953 --> 0.081569).  Saving model ...\n",
            "Epoch 11, Batch 1 loss: 0.088705\n",
            "Epoch: 11 \tTraining Loss: 0.134991 \tValidation Loss: 0.193223\n",
            "\n",
            "train Accuracy: 93.24% (634/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Epoch 12, Batch 1 loss: 0.208319\n",
            "Epoch: 12 \tTraining Loss: 0.165684 \tValidation Loss: 0.089797\n",
            "\n",
            "train Accuracy: 98.53% (670/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Epoch 13, Batch 1 loss: 0.161827\n",
            "Epoch: 13 \tTraining Loss: 0.117595 \tValidation Loss: 0.088774\n",
            "\n",
            "train Accuracy: 97.79% (665/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 14, Batch 1 loss: 0.060927\n",
            "Epoch: 14 \tTraining Loss: 0.146192 \tValidation Loss: 0.066379\n",
            "\n",
            "train Accuracy: 99.41% (676/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Validation loss decreased (0.081569 --> 0.066379).  Saving model ...\n",
            "Epoch 15, Batch 1 loss: 0.048707\n",
            "Epoch: 15 \tTraining Loss: 0.100198 \tValidation Loss: 0.086481\n",
            "\n",
            "train Accuracy: 97.94% (666/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 16, Batch 1 loss: 0.018848\n",
            "Epoch: 16 \tTraining Loss: 0.099890 \tValidation Loss: 0.082359\n",
            "\n",
            "train Accuracy: 97.65% (664/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 17, Batch 1 loss: 0.023166\n",
            "Epoch: 17 \tTraining Loss: 0.124305 \tValidation Loss: 0.117212\n",
            "\n",
            "train Accuracy: 96.18% (654/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Epoch 18, Batch 1 loss: 0.507819\n",
            "Epoch: 18 \tTraining Loss: 0.130839 \tValidation Loss: 0.085755\n",
            "\n",
            "train Accuracy: 97.35% (662/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 19, Batch 1 loss: 0.023477\n",
            "Epoch: 19 \tTraining Loss: 0.115361 \tValidation Loss: 0.078142\n",
            "\n",
            "train Accuracy: 98.09% (667/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 20, Batch 1 loss: 0.103930\n",
            "Epoch: 20 \tTraining Loss: 0.114513 \tValidation Loss: 0.121564\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 21, Batch 1 loss: 0.040558\n",
            "Epoch: 21 \tTraining Loss: 0.093482 \tValidation Loss: 0.149111\n",
            "\n",
            "train Accuracy: 94.26% (641/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Epoch 22, Batch 1 loss: 0.046710\n",
            "Epoch: 22 \tTraining Loss: 0.103291 \tValidation Loss: 0.087949\n",
            "\n",
            "train Accuracy: 97.21% (661/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 23, Batch 1 loss: 0.155352\n",
            "Epoch: 23 \tTraining Loss: 0.105488 \tValidation Loss: 0.073535\n",
            "\n",
            "train Accuracy: 97.94% (666/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Epoch 24, Batch 1 loss: 0.027283\n",
            "Epoch: 24 \tTraining Loss: 0.097792 \tValidation Loss: 0.054521\n",
            "\n",
            "train Accuracy: 99.71% (678/680)\n",
            "\n",
            " validation Accuracy: 97.94% (190/194)\n",
            "Validation loss decreased (0.066379 --> 0.054521).  Saving model ...\n",
            "Epoch 25, Batch 1 loss: 0.027912\n",
            "Epoch: 25 \tTraining Loss: 0.112802 \tValidation Loss: 0.085844\n",
            "\n",
            "train Accuracy: 97.79% (665/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-niyqC6N8159",
        "outputId": "7abe2379-9dea-4ec7-9351-76887086e947"
      },
      "source": [
        "model.load_state_dict(torch.load('alexnet.pt'))\n",
        "test(model, criterion, use_cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.032692\n",
            "\n",
            "\n",
            "Test Accuracy: 98.96907% (96/97)\n",
            "Precision=0.9915254237288136\n",
            "Recall=0.9871794871794872\n",
            "F1=0.9892329892329892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.96907216494846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qizLADJUC8pv",
        "outputId": "385aa66b-e25f-4463-9ed3-90c0982caf6a"
      },
      "source": [
        "model = models.googlenet(pretrained=True)\n",
        "#12 30\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "num_ftrs=model.fc.in_features\n",
        "\n",
        "#model.classifier[1]=nn.Conv2d(512,2,kernel_size=(1,1), stride=(1,1))\n",
        "\n",
        "model.fc= nn.Linear(num_ftrs, 2)\n",
        "\n",
        "fc_parameters = model.fc.parameters()\n",
        "for param in fc_parameters:\n",
        "    param.requires_grad = True\n",
        "\n",
        "model\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.001,momentum=0.9)\n",
        "train(25, model, optimizer, criterion, use_cuda, 'googlenet.pt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 1 loss: 0.732771\n",
            "Epoch: 1 \tTraining Loss: 0.591894 \tValidation Loss: 0.477058\n",
            "\n",
            "train Accuracy: 81.47% (554/680)\n",
            "\n",
            " validation Accuracy: 79.90% (155/194)\n",
            "Validation loss decreased (inf --> 0.477058).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 0.451280\n",
            "Epoch: 2 \tTraining Loss: 0.360547 \tValidation Loss: 0.329654\n",
            "\n",
            "train Accuracy: 90.15% (613/680)\n",
            "\n",
            " validation Accuracy: 87.63% (170/194)\n",
            "Validation loss decreased (0.477058 --> 0.329654).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 0.336085\n",
            "Epoch: 3 \tTraining Loss: 0.295348 \tValidation Loss: 0.288802\n",
            "\n",
            "train Accuracy: 91.32% (621/680)\n",
            "\n",
            " validation Accuracy: 88.14% (171/194)\n",
            "Validation loss decreased (0.329654 --> 0.288802).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 0.336581\n",
            "Epoch: 4 \tTraining Loss: 0.284162 \tValidation Loss: 0.264443\n",
            "\n",
            "train Accuracy: 91.47% (622/680)\n",
            "\n",
            " validation Accuracy: 90.21% (175/194)\n",
            "Validation loss decreased (0.288802 --> 0.264443).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 0.160299\n",
            "Epoch: 5 \tTraining Loss: 0.247433 \tValidation Loss: 0.245108\n",
            "\n",
            "train Accuracy: 92.94% (632/680)\n",
            "\n",
            " validation Accuracy: 91.75% (178/194)\n",
            "Validation loss decreased (0.264443 --> 0.245108).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 0.187229\n",
            "Epoch: 6 \tTraining Loss: 0.226540 \tValidation Loss: 0.235377\n",
            "\n",
            "train Accuracy: 93.82% (638/680)\n",
            "\n",
            " validation Accuracy: 92.27% (179/194)\n",
            "Validation loss decreased (0.245108 --> 0.235377).  Saving model ...\n",
            "Epoch 7, Batch 1 loss: 0.202696\n",
            "Epoch: 7 \tTraining Loss: 0.218885 \tValidation Loss: 0.226741\n",
            "\n",
            "train Accuracy: 93.97% (639/680)\n",
            "\n",
            " validation Accuracy: 92.27% (179/194)\n",
            "Validation loss decreased (0.235377 --> 0.226741).  Saving model ...\n",
            "Epoch 8, Batch 1 loss: 0.280108\n",
            "Epoch: 8 \tTraining Loss: 0.203298 \tValidation Loss: 0.211133\n",
            "\n",
            "train Accuracy: 94.85% (645/680)\n",
            "\n",
            " validation Accuracy: 92.27% (179/194)\n",
            "Validation loss decreased (0.226741 --> 0.211133).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 0.130681\n",
            "Epoch: 9 \tTraining Loss: 0.194884 \tValidation Loss: 0.209322\n",
            "\n",
            "train Accuracy: 95.59% (650/680)\n",
            "\n",
            " validation Accuracy: 93.30% (181/194)\n",
            "Validation loss decreased (0.211133 --> 0.209322).  Saving model ...\n",
            "Epoch 10, Batch 1 loss: 0.287064\n",
            "Epoch: 10 \tTraining Loss: 0.192455 \tValidation Loss: 0.197244\n",
            "\n",
            "train Accuracy: 95.88% (652/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Validation loss decreased (0.209322 --> 0.197244).  Saving model ...\n",
            "Epoch 11, Batch 1 loss: 0.147194\n",
            "Epoch: 11 \tTraining Loss: 0.180783 \tValidation Loss: 0.197985\n",
            "\n",
            "train Accuracy: 95.88% (652/680)\n",
            "\n",
            " validation Accuracy: 93.30% (181/194)\n",
            "Epoch 12, Batch 1 loss: 0.185621\n",
            "Epoch: 12 \tTraining Loss: 0.186875 \tValidation Loss: 0.182659\n",
            "\n",
            "train Accuracy: 96.47% (656/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Validation loss decreased (0.197244 --> 0.182659).  Saving model ...\n",
            "Epoch 13, Batch 1 loss: 0.138799\n",
            "Epoch: 13 \tTraining Loss: 0.174953 \tValidation Loss: 0.186372\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Epoch 14, Batch 1 loss: 0.135472\n",
            "Epoch: 14 \tTraining Loss: 0.163650 \tValidation Loss: 0.175663\n",
            "\n",
            "train Accuracy: 96.91% (659/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Validation loss decreased (0.182659 --> 0.175663).  Saving model ...\n",
            "Epoch 15, Batch 1 loss: 0.123985\n",
            "Epoch: 15 \tTraining Loss: 0.161132 \tValidation Loss: 0.175426\n",
            "\n",
            "train Accuracy: 96.47% (656/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Validation loss decreased (0.175663 --> 0.175426).  Saving model ...\n",
            "Epoch 16, Batch 1 loss: 0.149772\n",
            "Epoch: 16 \tTraining Loss: 0.164364 \tValidation Loss: 0.173459\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 93.30% (181/194)\n",
            "Validation loss decreased (0.175426 --> 0.173459).  Saving model ...\n",
            "Epoch 17, Batch 1 loss: 0.113293\n",
            "Epoch: 17 \tTraining Loss: 0.163217 \tValidation Loss: 0.168887\n",
            "\n",
            "train Accuracy: 96.91% (659/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Validation loss decreased (0.173459 --> 0.168887).  Saving model ...\n",
            "Epoch 18, Batch 1 loss: 0.146147\n",
            "Epoch: 18 \tTraining Loss: 0.150207 \tValidation Loss: 0.165604\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Validation loss decreased (0.168887 --> 0.165604).  Saving model ...\n",
            "Epoch 19, Batch 1 loss: 0.174798\n",
            "Epoch: 19 \tTraining Loss: 0.139909 \tValidation Loss: 0.169393\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Epoch 20, Batch 1 loss: 0.157659\n",
            "Epoch: 20 \tTraining Loss: 0.156504 \tValidation Loss: 0.165556\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Validation loss decreased (0.165604 --> 0.165556).  Saving model ...\n",
            "Epoch 21, Batch 1 loss: 0.118934\n",
            "Epoch: 21 \tTraining Loss: 0.143203 \tValidation Loss: 0.159139\n",
            "\n",
            "train Accuracy: 97.50% (663/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Validation loss decreased (0.165556 --> 0.159139).  Saving model ...\n",
            "Epoch 22, Batch 1 loss: 0.118942\n",
            "Epoch: 22 \tTraining Loss: 0.137248 \tValidation Loss: 0.166727\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Epoch 23, Batch 1 loss: 0.218793\n",
            "Epoch: 23 \tTraining Loss: 0.151778 \tValidation Loss: 0.159950\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 94.85% (184/194)\n",
            "Epoch 24, Batch 1 loss: 0.105492\n",
            "Epoch: 24 \tTraining Loss: 0.125124 \tValidation Loss: 0.157448\n",
            "\n",
            "train Accuracy: 97.65% (664/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Validation loss decreased (0.159139 --> 0.157448).  Saving model ...\n",
            "Epoch 25, Batch 1 loss: 0.073860\n",
            "Epoch: 25 \tTraining Loss: 0.128998 \tValidation Loss: 0.153514\n",
            "\n",
            "train Accuracy: 97.50% (663/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Validation loss decreased (0.157448 --> 0.153514).  Saving model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogLeNet(\n",
              "  (conv1): BasicConv2d(\n",
              "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (conv2): BasicConv2d(\n",
              "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (conv3): BasicConv2d(\n",
              "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception3a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception3b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception4a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4c): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4d): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4e): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception5a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception5b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (aux1): None\n",
              "  (aux2): None\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R08KHGABGJxy",
        "outputId": "87ff671b-b234-4e8f-bc80-12b7de2ba8b1"
      },
      "source": [
        "model.load_state_dict(torch.load('googlenet.pt'))\n",
        "test(model, criterion, use_cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.158632\n",
            "\n",
            "\n",
            "Test Accuracy: 94.84536% (92/97)\n",
            "Precision=0.9482604817127565\n",
            "Recall=0.9442970822281167\n",
            "F1=0.9461649461649462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.84536082474227"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c265041f4e944d4d83c80380b5e7cc7a",
            "ba79510f29ea44bea0f215df320d8908",
            "4dca1c1794ca4facae0483bef789d014",
            "91dcdd222a7847d5a0cccbf4287e3746",
            "1922b142ddc34a4fae4d800149042b85",
            "4ad7be4841744ed08180e2732c7e7da1",
            "c4189c15166547d1bf604ef28a2821b4",
            "841e0750830741798deb8584938f9f40"
          ]
        },
        "id": "dnUfkMdMW-8r",
        "outputId": "6b78d2c3-fa06-4b2a-c9f4-4cfb7cf5f3a5"
      },
      "source": [
        "model = models.vgg11(pretrained=True)\n",
        "#12 30\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        " \n",
        " \n",
        "num_ftrs=model.classifier[6].in_features\n",
        " \n",
        "#model.classifier[1]=nn.Conv2d(512,2,kernel_size=(1,1), stride=(1,1))\n",
        " \n",
        "model.classifier[6]= nn.Linear(num_ftrs, 2)\n",
        " \n",
        "fc_parameters = model.classifier[6].parameters()\n",
        "for param in fc_parameters:\n",
        "    param.requires_grad = True\n",
        " \n",
        "model\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.classifier[6].parameters(), lr=0.001,momentum=0.9)\n",
        "train(25, model, optimizer, criterion, use_cuda, 'vgg11.pt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg11-bbd30ac9.pth\" to /root/.cache/torch/hub/checkpoints/vgg11-bbd30ac9.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c265041f4e944d4d83c80380b5e7cc7a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=531456000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1, Batch 1 loss: 0.661966\n",
            "Epoch: 1 \tTraining Loss: 0.446897 \tValidation Loss: 0.290380\n",
            "\n",
            "train Accuracy: 87.94% (598/680)\n",
            "\n",
            " validation Accuracy: 87.11% (169/194)\n",
            "Validation loss decreased (inf --> 0.290380).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 0.322942\n",
            "Epoch: 2 \tTraining Loss: 0.322384 \tValidation Loss: 0.203490\n",
            "\n",
            "train Accuracy: 91.47% (622/680)\n",
            "\n",
            " validation Accuracy: 91.75% (178/194)\n",
            "Validation loss decreased (0.290380 --> 0.203490).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 0.303631\n",
            "Epoch: 3 \tTraining Loss: 0.289365 \tValidation Loss: 0.182292\n",
            "\n",
            "train Accuracy: 93.09% (633/680)\n",
            "\n",
            " validation Accuracy: 93.30% (181/194)\n",
            "Validation loss decreased (0.203490 --> 0.182292).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 0.280460\n",
            "Epoch: 4 \tTraining Loss: 0.250027 \tValidation Loss: 0.164016\n",
            "\n",
            "train Accuracy: 95.15% (647/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Validation loss decreased (0.182292 --> 0.164016).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 0.196898\n",
            "Epoch: 5 \tTraining Loss: 0.247427 \tValidation Loss: 0.150780\n",
            "\n",
            "train Accuracy: 93.38% (635/680)\n",
            "\n",
            " validation Accuracy: 93.30% (181/194)\n",
            "Validation loss decreased (0.164016 --> 0.150780).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 0.390273\n",
            "Epoch: 6 \tTraining Loss: 0.264195 \tValidation Loss: 0.160545\n",
            "\n",
            "train Accuracy: 92.65% (630/680)\n",
            "\n",
            " validation Accuracy: 92.78% (180/194)\n",
            "Epoch 7, Batch 1 loss: 0.206491\n",
            "Epoch: 7 \tTraining Loss: 0.206394 \tValidation Loss: 0.141678\n",
            "\n",
            "train Accuracy: 96.47% (656/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Validation loss decreased (0.150780 --> 0.141678).  Saving model ...\n",
            "Epoch 8, Batch 1 loss: 0.247957\n",
            "Epoch: 8 \tTraining Loss: 0.194540 \tValidation Loss: 0.137863\n",
            "\n",
            "train Accuracy: 93.97% (639/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Validation loss decreased (0.141678 --> 0.137863).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 0.355339\n",
            "Epoch: 9 \tTraining Loss: 0.205567 \tValidation Loss: 0.140436\n",
            "\n",
            "train Accuracy: 94.12% (640/680)\n",
            "\n",
            " validation Accuracy: 93.81% (182/194)\n",
            "Epoch 10, Batch 1 loss: 0.199284\n",
            "Epoch: 10 \tTraining Loss: 0.210614 \tValidation Loss: 0.194224\n",
            "\n",
            "train Accuracy: 92.50% (629/680)\n",
            "\n",
            " validation Accuracy: 92.27% (179/194)\n",
            "Epoch 11, Batch 1 loss: 0.422517\n",
            "Epoch: 11 \tTraining Loss: 0.195975 \tValidation Loss: 0.165841\n",
            "\n",
            "train Accuracy: 93.09% (633/680)\n",
            "\n",
            " validation Accuracy: 93.30% (181/194)\n",
            "Epoch 12, Batch 1 loss: 0.554165\n",
            "Epoch: 12 \tTraining Loss: 0.212903 \tValidation Loss: 0.104508\n",
            "\n",
            "train Accuracy: 96.76% (658/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Validation loss decreased (0.137863 --> 0.104508).  Saving model ...\n",
            "Epoch 13, Batch 1 loss: 0.227373\n",
            "Epoch: 13 \tTraining Loss: 0.162323 \tValidation Loss: 0.107778\n",
            "\n",
            "train Accuracy: 96.03% (653/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 14, Batch 1 loss: 0.027953\n",
            "Epoch: 14 \tTraining Loss: 0.194947 \tValidation Loss: 0.104592\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Epoch 15, Batch 1 loss: 0.133010\n",
            "Epoch: 15 \tTraining Loss: 0.185393 \tValidation Loss: 0.098567\n",
            "\n",
            "train Accuracy: 97.35% (662/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Validation loss decreased (0.104508 --> 0.098567).  Saving model ...\n",
            "Epoch 16, Batch 1 loss: 0.257887\n",
            "Epoch: 16 \tTraining Loss: 0.193415 \tValidation Loss: 0.134183\n",
            "\n",
            "train Accuracy: 94.26% (641/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Epoch 17, Batch 1 loss: 0.093113\n",
            "Epoch: 17 \tTraining Loss: 0.158855 \tValidation Loss: 0.105842\n",
            "\n",
            "train Accuracy: 95.74% (651/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 18, Batch 1 loss: 0.046255\n",
            "Epoch: 18 \tTraining Loss: 0.163908 \tValidation Loss: 0.096213\n",
            "\n",
            "train Accuracy: 96.62% (657/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.098567 --> 0.096213).  Saving model ...\n",
            "Epoch 19, Batch 1 loss: 0.068968\n",
            "Epoch: 19 \tTraining Loss: 0.154388 \tValidation Loss: 0.098026\n",
            "\n",
            "train Accuracy: 96.32% (655/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Epoch 20, Batch 1 loss: 0.118699\n",
            "Epoch: 20 \tTraining Loss: 0.169857 \tValidation Loss: 0.122381\n",
            "\n",
            "train Accuracy: 95.15% (647/680)\n",
            "\n",
            " validation Accuracy: 94.85% (184/194)\n",
            "Epoch 21, Batch 1 loss: 0.136754\n",
            "Epoch: 21 \tTraining Loss: 0.144764 \tValidation Loss: 0.089086\n",
            "\n",
            "train Accuracy: 96.62% (657/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Validation loss decreased (0.096213 --> 0.089086).  Saving model ...\n",
            "Epoch 22, Batch 1 loss: 0.049436\n",
            "Epoch: 22 \tTraining Loss: 0.167819 \tValidation Loss: 0.082627\n",
            "\n",
            "train Accuracy: 98.38% (669/680)\n",
            "\n",
            " validation Accuracy: 97.94% (190/194)\n",
            "Validation loss decreased (0.089086 --> 0.082627).  Saving model ...\n",
            "Epoch 23, Batch 1 loss: 0.125481\n",
            "Epoch: 23 \tTraining Loss: 0.162714 \tValidation Loss: 0.132170\n",
            "\n",
            "train Accuracy: 94.41% (642/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Epoch 24, Batch 1 loss: 0.025984\n",
            "Epoch: 24 \tTraining Loss: 0.155183 \tValidation Loss: 0.086172\n",
            "\n",
            "train Accuracy: 97.94% (666/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Epoch 25, Batch 1 loss: 0.197485\n",
            "Epoch: 25 \tTraining Loss: 0.139056 \tValidation Loss: 0.095942\n",
            "\n",
            "train Accuracy: 96.76% (658/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (14): ReLU(inplace=True)\n",
              "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoZrFt3aQOgQ",
        "outputId": "6db8eb74-dec7-4e89-ec49-b03d9c00b6ec"
      },
      "source": [
        "model.load_state_dict(torch.load('vgg11.pt'))\n",
        "test(model, criterion, use_cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.087695\n",
            "\n",
            "\n",
            "Test Accuracy: 96.90722% (94/97)\n",
            "Precision=0.969892952720785\n",
            "Recall=0.9657382847038019\n",
            "F1=0.9676989676989678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.90721649484536"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMtTsAcvtJvX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9b9bb6fee1f04a26829784abad05b422",
            "fb5cdc93fac341a28583e22412648f4c",
            "a0a988d6067246e680c196a497673f6f",
            "c9894ef3731c4c899419a0b497c113ef",
            "1cdafb8dc4814bee85df10c48841078b",
            "60fcdaf83354461ba085fe71945535b6",
            "af6ab9da84d94718a185c58cdd81d5e9",
            "c909c48f19a14e54af3b027162cefdd5"
          ]
        },
        "outputId": "6b852761-6705-403a-8b8b-42773e74133c"
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "#12 30\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        " \n",
        " \n",
        "num_ftrs=model.classifier[6].in_features\n",
        " \n",
        "#model.classifier[1]=nn.Conv2d(512,2,kernel_size=(1,1), stride=(1,1))\n",
        " \n",
        "model.classifier[6]= nn.Linear(num_ftrs, 2)\n",
        " \n",
        "fc_parameters = model.classifier[6].parameters()\n",
        "for param in fc_parameters:\n",
        "    param.requires_grad = True\n",
        " \n",
        "model\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.classifier[6].parameters(), lr=0.001,momentum=0.9)\n",
        "train(25, model, optimizer, criterion, use_cuda, 'vgg16.pt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b9bb6fee1f04a26829784abad05b422",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1, Batch 1 loss: 0.685569\n",
            "Epoch: 1 \tTraining Loss: 0.465006 \tValidation Loss: 0.275224\n",
            "\n",
            "train Accuracy: 90.44% (615/680)\n",
            "\n",
            " validation Accuracy: 90.21% (175/194)\n",
            "Validation loss decreased (inf --> 0.275224).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 0.329962\n",
            "Epoch: 2 \tTraining Loss: 0.292827 \tValidation Loss: 0.242486\n",
            "\n",
            "train Accuracy: 91.62% (623/680)\n",
            "\n",
            " validation Accuracy: 91.75% (178/194)\n",
            "Validation loss decreased (0.275224 --> 0.242486).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 0.367048\n",
            "Epoch: 3 \tTraining Loss: 0.254685 \tValidation Loss: 0.155563\n",
            "\n",
            "train Accuracy: 94.41% (642/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Validation loss decreased (0.242486 --> 0.155563).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 0.266138\n",
            "Epoch: 4 \tTraining Loss: 0.222212 \tValidation Loss: 0.141697\n",
            "\n",
            "train Accuracy: 94.85% (645/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Validation loss decreased (0.155563 --> 0.141697).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 0.232077\n",
            "Epoch: 5 \tTraining Loss: 0.217652 \tValidation Loss: 0.144285\n",
            "\n",
            "train Accuracy: 94.41% (642/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Epoch 6, Batch 1 loss: 0.345488\n",
            "Epoch: 6 \tTraining Loss: 0.206442 \tValidation Loss: 0.123902\n",
            "\n",
            "train Accuracy: 95.44% (649/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.141697 --> 0.123902).  Saving model ...\n",
            "Epoch 7, Batch 1 loss: 0.077149\n",
            "Epoch: 7 \tTraining Loss: 0.197041 \tValidation Loss: 0.119952\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Validation loss decreased (0.123902 --> 0.119952).  Saving model ...\n",
            "Epoch 8, Batch 1 loss: 0.284367\n",
            "Epoch: 8 \tTraining Loss: 0.192111 \tValidation Loss: 0.119871\n",
            "\n",
            "train Accuracy: 95.15% (647/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Validation loss decreased (0.119952 --> 0.119871).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 0.251952\n",
            "Epoch: 9 \tTraining Loss: 0.176648 \tValidation Loss: 0.120021\n",
            "\n",
            "train Accuracy: 96.91% (659/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Epoch 10, Batch 1 loss: 0.087122\n",
            "Epoch: 10 \tTraining Loss: 0.182095 \tValidation Loss: 0.104039\n",
            "\n",
            "train Accuracy: 97.35% (662/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Validation loss decreased (0.119871 --> 0.104039).  Saving model ...\n",
            "Epoch 11, Batch 1 loss: 0.380230\n",
            "Epoch: 11 \tTraining Loss: 0.158489 \tValidation Loss: 0.101491\n",
            "\n",
            "train Accuracy: 96.91% (659/680)\n",
            "\n",
            " validation Accuracy: 97.94% (190/194)\n",
            "Validation loss decreased (0.104039 --> 0.101491).  Saving model ...\n",
            "Epoch 12, Batch 1 loss: 0.139474\n",
            "Epoch: 12 \tTraining Loss: 0.137156 \tValidation Loss: 0.103769\n",
            "\n",
            "train Accuracy: 96.47% (656/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 13, Batch 1 loss: 0.120335\n",
            "Epoch: 13 \tTraining Loss: 0.187030 \tValidation Loss: 0.110902\n",
            "\n",
            "train Accuracy: 96.03% (653/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Epoch 14, Batch 1 loss: 0.138259\n",
            "Epoch: 14 \tTraining Loss: 0.169528 \tValidation Loss: 0.181181\n",
            "\n",
            "train Accuracy: 93.09% (633/680)\n",
            "\n",
            " validation Accuracy: 91.75% (178/194)\n",
            "Epoch 15, Batch 1 loss: 0.338669\n",
            "Epoch: 15 \tTraining Loss: 0.197521 \tValidation Loss: 0.097987\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Validation loss decreased (0.101491 --> 0.097987).  Saving model ...\n",
            "Epoch 16, Batch 1 loss: 0.129919\n",
            "Epoch: 16 \tTraining Loss: 0.153968 \tValidation Loss: 0.095426\n",
            "\n",
            "train Accuracy: 96.47% (656/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.097987 --> 0.095426).  Saving model ...\n",
            "Epoch 17, Batch 1 loss: 0.214083\n",
            "Epoch: 17 \tTraining Loss: 0.152902 \tValidation Loss: 0.095261\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.095426 --> 0.095261).  Saving model ...\n",
            "Epoch 18, Batch 1 loss: 0.051789\n",
            "Epoch: 18 \tTraining Loss: 0.141028 \tValidation Loss: 0.094123\n",
            "\n",
            "train Accuracy: 96.76% (658/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.095261 --> 0.094123).  Saving model ...\n",
            "Epoch 19, Batch 1 loss: 0.050629\n",
            "Epoch: 19 \tTraining Loss: 0.149187 \tValidation Loss: 0.110134\n",
            "\n",
            "train Accuracy: 96.03% (653/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Epoch 20, Batch 1 loss: 0.109964\n",
            "Epoch: 20 \tTraining Loss: 0.160375 \tValidation Loss: 0.090767\n",
            "\n",
            "train Accuracy: 98.24% (668/680)\n",
            "\n",
            " validation Accuracy: 97.94% (190/194)\n",
            "Validation loss decreased (0.094123 --> 0.090767).  Saving model ...\n",
            "Epoch 21, Batch 1 loss: 0.048493\n",
            "Epoch: 21 \tTraining Loss: 0.135218 \tValidation Loss: 0.087859\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 96.91% (188/194)\n",
            "Validation loss decreased (0.090767 --> 0.087859).  Saving model ...\n",
            "Epoch 22, Batch 1 loss: 0.234750\n",
            "Epoch: 22 \tTraining Loss: 0.166742 \tValidation Loss: 0.084439\n",
            "\n",
            "train Accuracy: 97.35% (662/680)\n",
            "\n",
            " validation Accuracy: 97.42% (189/194)\n",
            "Validation loss decreased (0.087859 --> 0.084439).  Saving model ...\n",
            "Epoch 23, Batch 1 loss: 0.181236\n",
            "Epoch: 23 \tTraining Loss: 0.161757 \tValidation Loss: 0.121992\n",
            "\n",
            "train Accuracy: 94.85% (645/680)\n",
            "\n",
            " validation Accuracy: 94.33% (183/194)\n",
            "Epoch 24, Batch 1 loss: 0.246345\n",
            "Epoch: 24 \tTraining Loss: 0.147782 \tValidation Loss: 0.095936\n",
            "\n",
            "train Accuracy: 98.09% (667/680)\n",
            "\n",
            " validation Accuracy: 97.94% (190/194)\n",
            "Epoch 25, Batch 1 loss: 0.187718\n",
            "Epoch: 25 \tTraining Loss: 0.177575 \tValidation Loss: 0.085338\n",
            "\n",
            "train Accuracy: 98.24% (668/680)\n",
            "\n",
            " validation Accuracy: 97.94% (190/194)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcwnPS39aO5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd1ea36-a5d2-42a0-fdb8-077fdcb0fef3"
      },
      "source": [
        "model.load_state_dict(torch.load('vgg16.pt'))\n",
        "test(model, criterion, use_cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.072318\n",
            "\n",
            "\n",
            "Test Accuracy: 98.96907% (96/97)\n",
            "Precision=0.9875\n",
            "Recall=0.9913793103448276\n",
            "F1=0.9893230599889928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.96907216494846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_gdQHkK4VDh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "13c1cf499cca450199193ece5a66d783",
            "d32d8616aba84540a97a71e6179a31c8",
            "b5a51125215246e9b6c0acaf84e0d71c",
            "e3871cff84744ef4ba165a06017fc64c",
            "e04b636bb33b4a7793a0ecb064050fc5",
            "51ac87b23971469a851d9e9d93fed207",
            "b8814c1990e1499eac510a1eb8b1c8e0",
            "6e1c3294528e42f2a0559dba3105a76c"
          ]
        },
        "outputId": "58226a48-54a5-4e3e-9560-9a2c53919795"
      },
      "source": [
        "model = models.vgg19(pretrained=True)\n",
        "#12 30\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        " \n",
        " \n",
        "num_ftrs=model.classifier[6].in_features\n",
        " \n",
        "#model.classifier[1]=nn.Conv2d(512,2,kernel_size=(1,1), stride=(1,1))\n",
        " \n",
        "model.classifier[6]= nn.Linear(num_ftrs, 2)\n",
        " \n",
        "fc_parameters = model.classifier[6].parameters()\n",
        "for param in fc_parameters:\n",
        "    param.requires_grad = True\n",
        " \n",
        "model\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.classifier[6].parameters(), lr=0.001,momentum=0.9)\n",
        "train(25, model, optimizer, criterion, use_cuda, 'vgg19.pt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13c1cf499cca450199193ece5a66d783",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=574673361.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1, Batch 1 loss: 0.673606\n",
            "Epoch: 1 \tTraining Loss: 0.431861 \tValidation Loss: 0.248724\n",
            "\n",
            "train Accuracy: 88.09% (599/680)\n",
            "\n",
            " validation Accuracy: 89.18% (173/194)\n",
            "Validation loss decreased (inf --> 0.248724).  Saving model ...\n",
            "Epoch 2, Batch 1 loss: 0.178911\n",
            "Epoch: 2 \tTraining Loss: 0.259631 \tValidation Loss: 0.177445\n",
            "\n",
            "train Accuracy: 93.38% (635/680)\n",
            "\n",
            " validation Accuracy: 92.27% (179/194)\n",
            "Validation loss decreased (0.248724 --> 0.177445).  Saving model ...\n",
            "Epoch 3, Batch 1 loss: 0.264376\n",
            "Epoch: 3 \tTraining Loss: 0.227441 \tValidation Loss: 0.152263\n",
            "\n",
            "train Accuracy: 94.41% (642/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Validation loss decreased (0.177445 --> 0.152263).  Saving model ...\n",
            "Epoch 4, Batch 1 loss: 0.594169\n",
            "Epoch: 4 \tTraining Loss: 0.237262 \tValidation Loss: 0.147996\n",
            "\n",
            "train Accuracy: 93.97% (639/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Validation loss decreased (0.152263 --> 0.147996).  Saving model ...\n",
            "Epoch 5, Batch 1 loss: 0.224884\n",
            "Epoch: 5 \tTraining Loss: 0.196088 \tValidation Loss: 0.146257\n",
            "\n",
            "train Accuracy: 96.62% (657/680)\n",
            "\n",
            " validation Accuracy: 94.85% (184/194)\n",
            "Validation loss decreased (0.147996 --> 0.146257).  Saving model ...\n",
            "Epoch 6, Batch 1 loss: 0.189401\n",
            "Epoch: 6 \tTraining Loss: 0.208045 \tValidation Loss: 0.138879\n",
            "\n",
            "train Accuracy: 96.47% (656/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Validation loss decreased (0.146257 --> 0.138879).  Saving model ...\n",
            "Epoch 7, Batch 1 loss: 0.181283\n",
            "Epoch: 7 \tTraining Loss: 0.167788 \tValidation Loss: 0.137075\n",
            "\n",
            "train Accuracy: 93.97% (639/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Validation loss decreased (0.138879 --> 0.137075).  Saving model ...\n",
            "Epoch 8, Batch 1 loss: 0.178448\n",
            "Epoch: 8 \tTraining Loss: 0.180730 \tValidation Loss: 0.118837\n",
            "\n",
            "train Accuracy: 97.21% (661/680)\n",
            "\n",
            " validation Accuracy: 95.36% (185/194)\n",
            "Validation loss decreased (0.137075 --> 0.118837).  Saving model ...\n",
            "Epoch 9, Batch 1 loss: 0.155266\n",
            "Epoch: 9 \tTraining Loss: 0.173681 \tValidation Loss: 0.128967\n",
            "\n",
            "train Accuracy: 94.26% (641/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 10, Batch 1 loss: 0.246222\n",
            "Epoch: 10 \tTraining Loss: 0.166220 \tValidation Loss: 0.112606\n",
            "\n",
            "train Accuracy: 95.88% (652/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Validation loss decreased (0.118837 --> 0.112606).  Saving model ...\n",
            "Epoch 11, Batch 1 loss: 0.420227\n",
            "Epoch: 11 \tTraining Loss: 0.182915 \tValidation Loss: 0.116054\n",
            "\n",
            "train Accuracy: 95.74% (651/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 12, Batch 1 loss: 0.360056\n",
            "Epoch: 12 \tTraining Loss: 0.164270 \tValidation Loss: 0.106629\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Validation loss decreased (0.112606 --> 0.106629).  Saving model ...\n",
            "Epoch 13, Batch 1 loss: 0.449059\n",
            "Epoch: 13 \tTraining Loss: 0.178688 \tValidation Loss: 0.106306\n",
            "\n",
            "train Accuracy: 97.06% (660/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Validation loss decreased (0.106629 --> 0.106306).  Saving model ...\n",
            "Epoch 14, Batch 1 loss: 0.109496\n",
            "Epoch: 14 \tTraining Loss: 0.196555 \tValidation Loss: 0.113422\n",
            "\n",
            "train Accuracy: 95.29% (648/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 15, Batch 1 loss: 0.037430\n",
            "Epoch: 15 \tTraining Loss: 0.165106 \tValidation Loss: 0.116390\n",
            "\n",
            "train Accuracy: 95.59% (650/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 16, Batch 1 loss: 0.049550\n",
            "Epoch: 16 \tTraining Loss: 0.143926 \tValidation Loss: 0.109668\n",
            "\n",
            "train Accuracy: 97.35% (662/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 17, Batch 1 loss: 0.022680\n",
            "Epoch: 17 \tTraining Loss: 0.148916 \tValidation Loss: 0.114698\n",
            "\n",
            "train Accuracy: 95.74% (651/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 18, Batch 1 loss: 0.077809\n",
            "Epoch: 18 \tTraining Loss: 0.127067 \tValidation Loss: 0.114427\n",
            "\n",
            "train Accuracy: 95.59% (650/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 19, Batch 1 loss: 0.242303\n",
            "Epoch: 19 \tTraining Loss: 0.156923 \tValidation Loss: 0.097325\n",
            "\n",
            "train Accuracy: 96.91% (659/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Validation loss decreased (0.106306 --> 0.097325).  Saving model ...\n",
            "Epoch 20, Batch 1 loss: 0.048238\n",
            "Epoch: 20 \tTraining Loss: 0.154662 \tValidation Loss: 0.104192\n",
            "\n",
            "train Accuracy: 96.32% (655/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 21, Batch 1 loss: 0.187836\n",
            "Epoch: 21 \tTraining Loss: 0.162300 \tValidation Loss: 0.103245\n",
            "\n",
            "train Accuracy: 96.76% (658/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 22, Batch 1 loss: 0.208622\n",
            "Epoch: 22 \tTraining Loss: 0.132583 \tValidation Loss: 0.099642\n",
            "\n",
            "train Accuracy: 98.09% (667/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Epoch 23, Batch 1 loss: 0.273455\n",
            "Epoch: 23 \tTraining Loss: 0.162714 \tValidation Loss: 0.130951\n",
            "\n",
            "train Accuracy: 94.71% (644/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n",
            "Epoch 24, Batch 1 loss: 0.200751\n",
            "Epoch: 24 \tTraining Loss: 0.143795 \tValidation Loss: 0.095560\n",
            "\n",
            "train Accuracy: 96.76% (658/680)\n",
            "\n",
            " validation Accuracy: 96.39% (187/194)\n",
            "Validation loss decreased (0.097325 --> 0.095560).  Saving model ...\n",
            "Epoch 25, Batch 1 loss: 0.155181\n",
            "Epoch: 25 \tTraining Loss: 0.154592 \tValidation Loss: 0.103190\n",
            "\n",
            "train Accuracy: 95.88% (652/680)\n",
            "\n",
            " validation Accuracy: 95.88% (186/194)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): ReLU(inplace=True)\n",
              "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (33): ReLU(inplace=True)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): ReLU(inplace=True)\n",
              "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtvxE6KHKGhK",
        "outputId": "d45a76d9-5df4-47a0-bed7-969471ca0012"
      },
      "source": [
        "model.load_state_dict(torch.load('vgg19.pt'))\n",
        "test(model, criterion, use_cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.102882\n",
            "\n",
            "\n",
            "Test Accuracy: 95.87629% (93/97)\n",
            "Precision=0.95448606271777\n",
            "Recall=0.9613174182139699\n",
            "F1=0.9574561403508772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95.87628865979381"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}